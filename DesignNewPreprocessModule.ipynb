{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.ETLBase import PipelineBuilder, PipeConfigBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO THIS IF CODE Config and Pipe Connection in define in the main function \n",
    "def func(code_str):\n",
    "    exec(code_str, globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func('a=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test:\n",
    "    def __init__(self):\n",
    "        pass \n",
    "    def str_2_code(self, var, expression):\n",
    "        exec(f'self.{var}={expression}')\n",
    "    def set_public_var(self, var, expression):\n",
    "        self.str_2_code(var, expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.set_public_var('a', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_exec = exec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_exec('a = 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Allow visualization of configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PipeConfigBuilder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_two(add_t=0):\n",
    "    return 5 + add_t, 2\n",
    "def test(b=2):\n",
    "    return b + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_t = config.add('add_t', 3)\n",
    "x = config.add('x', 5)\n",
    "config.view(summary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec('t = 4') \n",
    "# 可以用這個方法把要assign 的變數都assign 好 ! # 讓config 可以直接以一個dictionary去建立 \n",
    "# 或是pass in **kwargs的方式吃進來。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = PipelineBuilder(config)\n",
    "# add_t = lambda: 3\n",
    "# add_t = pipe.add(add_t, method_alias = 'add_t=3', output_alias = 'add_t', color='gray')()\n",
    "b, d = pipe.add(one_two, output_alias=['b', 'd'], n_out = 2)(add_t = add_t)\n",
    "d = pipe.add(test, output_alias = 'd')(b=b)\n",
    "pipe.view(summary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.ex3.preprocess_modules import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "origin_path = 'data/source'\n",
    "sample_path = 'data/sample'\n",
    "\n",
    "tmp_path = 'data/tmp' # 'data/tmp'\n",
    "result_path = 'data/result' # 'data/result'\n",
    "\n",
    "\n",
    "# ETL configuration >\n",
    "\n",
    "# easily assign configuration using 'Config Builder Object' \n",
    "# it initialize using pipe_config = PipeConfigBuilder()\n",
    "# add config variable using var = pipe_config.add(name='var', value=50)\n",
    "# \n",
    "\n",
    "config = PipeConfigBuilder()\n",
    "\n",
    "chid_file = config.add('chid_file', os.path.join(origin_path, 'sample_chid.txt'))\n",
    "cdtx_file = config.add('cdtx_file', os.path.join(origin_path, 'sample_zip_if_cca_cdtx0001_hist.csv'))\n",
    "cust_f_file = config.add('cust_f_file', os.path.join(origin_path, 'sample_zip_if_cca_cust_f.csv'))\n",
    "\n",
    "\n",
    "n_sample = config.add('n_sample', 50) #50\n",
    "\n",
    "window_size = config.add('window_size', 120)# 120 \n",
    "\n",
    "test_size = config.add('test_size', 2)\n",
    "\n",
    "CATEGORY_COLS = ['chid', 'bnsfg', 'iterm', 'mcc', 'scity']\n",
    "NUMERIC_COLS = ['bnspt', 'timestamp_0', 'timestamp_1', 'objam']\n",
    "\n",
    "category_cols = config.add('category_cols', CATEGORY_COLS) # ETL Variable \n",
    "numeric_cols = config.add('numeric_cols', NUMERIC_COLS) # ETL Variable \n",
    "\n",
    "LEFT = config.add('LEFT','left')\n",
    "INNER = config.add('INNER', 'inner')\n",
    "time_column_data_dt = config.add('time_column_data_dt', 'data_dt')\n",
    "time_column_csmdt = config.add('time_column_csmdt','csmdt')\n",
    "result_column_timestamp_1 = config.add('result_column_timestamp_1', 'timestamp_1')\n",
    "result_column_timestamp_0 = config.add('result_column_timestamp_0', 'timestamp_0')\n",
    "result_column_timestamp = config.add('result_column_timestamp', 'timestamp')\n",
    "\n",
    "cust_numeric_cols = config.add('cust_numeric_cols', ['slam', 'first_mob', 'constant_change', 'sum_l2_ind',\n",
    "                  'sum_u2_ind', 'constant_l2_ind', 'constant_u4_ind',\n",
    "                  'growth_rate', 'monotone_down', 'monotone_up', 'data_dt'])\n",
    "cust_category_cols = config.add('cust_category_cols', ['chid', 'masts', 'educd', 'trdtp', 'poscd'])\n",
    "target_cols = config.add('target_cols', ['chid', 'data_dt', 'objam_sum', 'objam_mean', 'trans_count', 'objam_mean_M3'])\n",
    "\n",
    "# < ETL configuration\n",
    "\n",
    "sparse_feat = ['chid', 'bnsfg', 'iterm', 'mcc', 'scity']\n",
    "dense_feat = ['bnspt', 'timestamp_0', 'timestamp_1', 'objam']\n",
    "USE_CHID = True\n",
    "\n",
    "sparse_dense_setting_generator = GenerateSparseDenseSetting(\n",
    "    category_cols=CATEGORY_COLS, \n",
    "    sparse_feat=sparse_feat, \n",
    "    numeric_cols=NUMERIC_COLS, \n",
    "    dense_feat=dense_feat, \n",
    "    USE_CHID=USE_CHID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = PipelineBuilder(config)\n",
    "chids = pipe.add(load_chids, output_alias = 'chids')(chid_file = chid_file)\n",
    "\n",
    "sampled_chids = pipe.add(\n",
    "    sample_chids, \n",
    "    output_alias = 'sampled_chids', \n",
    "    result_dir = os.path.join(sample_path,'sampled_chids.npy')\n",
    ")(chids, n_sample = n_sample)\n",
    "pipe.view(summary = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.view_dependency('sample_chids', summary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chid_to_nid_map = pipe.add(build_chid_to_nid_map, output_alias = 'chid_to_nid_map')(\n",
    "    sampled_chids\n",
    ")\n",
    "df_cdtx = pipe.add(load_cdtx, output_alias = 'df_cdtx')(\n",
    "    sampled_chids, \n",
    "    cdtx_file = cdtx_file\n",
    ")\n",
    "df_cdtx = pipe.add(convert_uid_to_nid, output_alias = 'df_cdtx')(\n",
    "    df_cdtx, \n",
    "    chid_to_nid_map\n",
    ")\n",
    "df_cdtx = pipe.add(add_month, \n",
    "                 output_alias = 'df_cdtx', \n",
    "                 result_dir = os.path.join(tmp_path, 'df_cdtx.feather')\n",
    "                )(df_cdtx)\n",
    "\n",
    "df_full_y_sum = pipe.add(\n",
    "    make_chid_x_month_table, \n",
    "    output_alias = 'df_full_y_sum'\n",
    ")(\n",
    "    df_cdtx\n",
    ")\n",
    "\n",
    "df_cdtx_monthly_objam = pipe.add(calculate_monthly_target, output_alias = 'df_cdtx_monthly_objam')(\n",
    "    df_cdtx\n",
    ")\n",
    "\n",
    "df_full_y_sum = pipe.add(merge_with_another_table, output_alias = 'df_full_y_sum')(\n",
    "    df_full_y_sum, \n",
    "    df_cdtx_monthly_objam, \n",
    "    join_method=LEFT\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "df_cust_f = pipe.add(load_cust_f, output_alias = 'df_cust_f')(\n",
    "    sampled_chids, \n",
    "    cust_f_file = cust_f_file\n",
    ")\n",
    "\n",
    "df_cust_f = pipe.add(\n",
    "    convert_uid_to_nid, \n",
    "    output_alias = 'df_cust_f', \n",
    "    result_dir = os.path.join(tmp_path, 'df_cust_f.feather')\n",
    ")(\n",
    "    df_cust_f, \n",
    "    chid_to_nid_map\n",
    ")\n",
    "\n",
    "df_full_y_sum = pipe.add(merge_with_another_table, output_alias = 'df_full_y_sum')(\n",
    "    df_full_y_sum, df_cust_f, join_method=INNER)\n",
    "\n",
    "\n",
    "\n",
    "df_full_y_sum = pipe.add(add_mean_of_previous_two_months, output_alias = 'df_full_y_sum')(\n",
    "    df_full_y_sum)\n",
    "\n",
    "\n",
    "\n",
    "df_full_y_sum = pipe.add(cast_time_column_to_np_datatime64, output_alias = 'df_full_y_sum')(\n",
    "    df_full_y_sum, time_column = time_column_data_dt)\n",
    "\n",
    "\n",
    "\n",
    "df_cdtx = pipe.add(cast_time_column_to_np_datatime64, output_alias = 'df_cdtx')(\n",
    "    df_cdtx, time_column = time_column_csmdt)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_cdtx = pipe.add(add_duration_since_20180101, output_alias = 'df_cdtx')(\n",
    "    df_cdtx, time_column = time_column_csmdt, result_column=result_column_timestamp_1)\n",
    "\n",
    "\n",
    "df_cdtx = pipe.add(add_duration_since_last_trans, output_alias = 'df_cdtx')(\n",
    "    df_cdtx, time_column = time_column_csmdt, result_column=result_column_timestamp_0)\n",
    "\n",
    "\n",
    "df_input, feature_map = pipe.add(\n",
    "    extract_feature_cols_and_encode_categoricals, \n",
    "    n_out = 2, \n",
    "    output_alias = ['df_input', 'feature_map'], \n",
    "    result_dir=[\n",
    "                os.path.join(tmp_path, 'df_input.feather'),\n",
    "                os.path.join(tmp_path, 'feature_map.npy')\n",
    "            ]\n",
    ")(\n",
    "    df_cdtx, \n",
    "    numeric_cols=numeric_cols,\n",
    "    category_cols=category_cols\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_feat_input, cust_feature_map = pipe.add(\n",
    "    extract_feature_cols_and_encode_categoricals, \n",
    "    n_out = 2, \n",
    "    output_alias = ['df_feat_input', 'cust_feature_map'], \n",
    "    result_dir=[\n",
    "                os.path.join(tmp_path, 'df_feat_input.1.feather'),\n",
    "                os.path.join(tmp_path, 'cust_feature_map.npy')\n",
    "            ]\n",
    ")(\n",
    "    df_cust_f, \n",
    "    numeric_cols=cust_numeric_cols,\n",
    "    category_cols=cust_category_cols\n",
    ")\n",
    "\n",
    "df_feat_input = pipe.add(cast_time_column_to_np_datatime64, output_alias = 'df_feat_input')(\n",
    "    df_feat_input, time_column = 'data_dt')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_feat_input = pipe.add(\n",
    "    add_duration_since_20180101, \n",
    "    output_alias = 'df_feat_input', \n",
    "    result_dir = os.path.join(tmp_path, 'df_feat_input.2.feather')\n",
    ")(\n",
    "    df_feat_input, time_column = time_column_data_dt, result_column=result_column_timestamp)\n",
    "\n",
    "df_y = pipe.add(extract_target_columns, output_alias = 'df_y')(\n",
    "    df_full_y_sum,\n",
    "    target_cols=target_cols,  # 'shop_count'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_y = pipe.add(\n",
    "    add_duration_since_20180101, \n",
    "    output_alias = 'df_y', \n",
    "    result_dir = os.path.join(tmp_path, 'df_y.feather')\n",
    ")(\n",
    "    df_y, time_column = time_column_data_dt, result_column=result_column_timestamp)\n",
    "\n",
    "pipe.view(summary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_feature_map.get(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.view_dependency('calculate_monthly_target', summary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# split_data\n",
    "# add_objam_mean_M3_diff_as_new_target\n",
    "# extract_x_f_y_columns\n",
    "\n",
    "x_train, x_test, f_train, f_test, y_train, y_test = pipe.add(\n",
    "    split_data, \n",
    "    n_out = 6,\n",
    "    output_alias = ['x_train', 'x_test', 'f_train', 'f_test', 'y_train', 'y_test'],\n",
    "    result_dir=[\n",
    "                os.path.join(tmp_path, 'x_train.npy'),\n",
    "                os.path.join(tmp_path, 'x_test.npy'),\n",
    "                os.path.join(tmp_path, 'f_train.npy'),\n",
    "                os.path.join(tmp_path, 'f_test.npy'),\n",
    "                os.path.join(tmp_path, 'y_train.npy'),\n",
    "                os.path.join(tmp_path, 'y_test.npy')\n",
    "            ]\n",
    ")(df_input, df_feat_input, df_y, window_size = window_size, test_size = test_size)\n",
    "\n",
    "\n",
    "y_train, y_test, y_columns = pipe.add(\n",
    "    add_objam_mean_M3_diff_as_new_target, \n",
    "    n_out = 3,\n",
    "    output_alias = ['y_train', 'y_test', 'y_columns'],\n",
    "    result_dir = [\n",
    "        os.path.join(tmp_path, 'y_train.npy'),\n",
    "        os.path.join(tmp_path, 'y_test.npy'),\n",
    "        os.path.join(tmp_path, 'y_columns.npy')\n",
    "    ]\n",
    ")(df_y, y_train, y_test)\n",
    "\n",
    "columns = pipe.add(extract_x_f_y_columns, output_alias = 'columns')(\n",
    "    df_input, df_feat_input, y_columns\n",
    ")\n",
    "\n",
    "\n",
    "'''\n",
    "for output in [x_train, x_test, f_train, f_test, y_train, y_test, columns, feature_map, cust_feature_map, chid_to_nid_map]:\n",
    "    output.get()\n",
    "'''\n",
    "pipe.view(summary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sparse_dims, sparse_index, dense_dims, dense_index = pipe.add(\n",
    "    sparse_dense_setting_generator.process,\n",
    "    method_alias = 'generate_sparse_dense_setting',\n",
    "    n_out = 4, \n",
    "    output_alias = ['sparse_dims', 'sparse_index', 'dense_dims', 'dense_index']\n",
    ")(\n",
    "    feature_map, chid_to_nid_map\n",
    ")\n",
    "\n",
    "x_train_sparse, x_train_dense, x_test_sparse, x_test_dense = pipe.add(\n",
    "    ProcessX.process,\n",
    "    method_alias = 'ProcessX.process',\n",
    "    n_out = 4, \n",
    "    output_alias = ['x_train_sparse', 'x_train_dense', 'x_test_sparse', 'x_test_dense']\n",
    ")(\n",
    "    x_train, x_test, sparse_index, dense_index\n",
    ")\n",
    "\n",
    "train_objmean, train_tscnt, train_label_0, test_objmean, test_tscnt, test_label_0 = pipe.add(\n",
    "    ProcessY.process,\n",
    "    method_alias = 'ProcessY.process',\n",
    "    n_out = 6, \n",
    "    output_alias = ['train_objmean', 'train_tscnt', 'train_label_0', 'test_objmean', 'test_tscnt', 'test_label_0']\n",
    ")(\n",
    "    y_train, y_test, columns\n",
    ")\n",
    "\n",
    "train_dataset = pipe.add(\n",
    "    build_TensorDataset,\n",
    "    output_alias = 'train_dataset'\n",
    ")(\n",
    "    x_train_dense, x_train_sparse, train_objmean, train_tscnt, train_label_0\n",
    ")\n",
    "    \n",
    "test_dataset = pipe.add(\n",
    "    build_TensorDataset,\n",
    "    output_alias = 'test_dataset'\n",
    ")(\n",
    "    x_test_dense, x_test_sparse, test_objmean, test_tscnt, test_label_0\n",
    ")\n",
    "pipe.view(summary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.view_dependency('split_data', summary=False, gap=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.run(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
