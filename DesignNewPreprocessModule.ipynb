{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.ETLBase import PipelineBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyflow import GraphBuilder\n",
    "pipe = PipelineBuilder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_two():\n",
    "    return 5, 2\n",
    "def test(b=2):\n",
    "    return b + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"81pt\" height=\"178pt\"\n",
       " viewBox=\"0.00 0.00 80.50 178.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 174)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-174 76.5,-174 76.5,4 -4,4\"/>\n",
       "<!-- one_two_0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>one_two_0</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"72.5,-170 5.5,-170 5.5,-149 72.5,-149 72.5,-170\"/>\n",
       "<text text-anchor=\"middle\" x=\"39\" y=\"-156.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">one_two</text>\n",
       "</g>\n",
       "<!-- b_1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>b_1</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"30.5,-119 7.5,-119 7.5,-100 30.5,-100 30.5,-119\"/>\n",
       "<text text-anchor=\"middle\" x=\"19\" y=\"-107\" font-family=\"Times,serif\" font-size=\"10.00\" fill=\"#000000\">b</text>\n",
       "</g>\n",
       "<!-- one_two_0&#45;&gt;b_1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>one_two_0&#45;&gt;b_1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M34.7585,-148.8963C32.3857,-142.9642 29.3567,-135.3916 26.5895,-128.4737\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"29.7932,-127.0588 22.8296,-119.074 23.2939,-129.6586 29.7932,-127.0588\"/>\n",
       "</g>\n",
       "<!-- d_2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>d_2</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"71.5,-119 48.5,-119 48.5,-100 71.5,-100 71.5,-119\"/>\n",
       "<text text-anchor=\"middle\" x=\"60\" y=\"-107\" font-family=\"Times,serif\" font-size=\"10.00\" fill=\"#000000\">d</text>\n",
       "</g>\n",
       "<!-- one_two_0&#45;&gt;d_2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>one_two_0&#45;&gt;d_2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M43.4536,-148.8963C45.945,-142.9642 49.1255,-135.3916 52.031,-128.4737\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"55.3335,-129.6491 55.9789,-119.074 48.8796,-126.9385 55.3335,-129.6491\"/>\n",
       "</g>\n",
       "<!-- test_3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>test_3</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"38,-70 0,-70 0,-49 38,-49 38,-70\"/>\n",
       "<text text-anchor=\"middle\" x=\"19\" y=\"-56.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">test</text>\n",
       "</g>\n",
       "<!-- b_1&#45;&gt;test_3 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>b_1&#45;&gt;test_3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M19,-99.8595C19,-94.2726 19,-87.0149 19,-80.1973\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"22.5001,-80.1496 19,-70.1496 15.5001,-80.1496 22.5001,-80.1496\"/>\n",
       "</g>\n",
       "<!-- d_4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>d_4</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"30.5,-19 7.5,-19 7.5,0 30.5,0 30.5,-19\"/>\n",
       "<text text-anchor=\"middle\" x=\"19\" y=\"-7\" font-family=\"Times,serif\" font-size=\"10.00\" fill=\"#000000\">d</text>\n",
       "</g>\n",
       "<!-- test_3&#45;&gt;d_4 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>test_3&#45;&gt;d_4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M19,-48.8963C19,-43.2401 19,-36.0925 19,-29.443\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"22.5001,-29.0739 19,-19.074 15.5001,-29.074 22.5001,-29.0739\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f750ba51c50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b, d = pipe.add(one_two, output_alias=['b', 'd'], n_out = 2)()\n",
    "d = pipe.add(test, output_alias = 'd')(b=b)\n",
    "pipe.view(summary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.pf_output_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.ETLBase import DataNode\n",
    "# if kwargs has the following type of objects, replace them with .pf_output_node \n",
    "type(b).__name__ == 'DataNode+ETLBase'\n",
    "type(b).__name__ == 'SelectResult+ETLBase'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.ex3.preprocess_modules import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "origin_path = 'data/source'\n",
    "sample_path = 'data/sample'\n",
    "\n",
    "tmp_path = 'data/tmp' # 'data/tmp'\n",
    "result_path = 'data/result' # 'data/result'\n",
    "\n",
    "n_sample = 50\n",
    "window_size = 120 \n",
    "test_size = 2\n",
    "\n",
    "chid_file = os.path.join(origin_path, 'sample_chid.txt')\n",
    "def chid_file_path():\n",
    "    return chid_file\n",
    "cdtx_file = os.path.join(origin_path, 'sample_zip_if_cca_cdtx0001_hist.csv')\n",
    "cust_f_file = os.path.join(origin_path, 'sample_zip_if_cca_cust_f.csv')\n",
    "\n",
    "numeric_cols = ['bnspt', 'timestamp_0', 'timestamp_1', 'objam'], \n",
    "category_cols = ['chid', 'bnsfg', 'iterm', 'mcc', 'scity'], \n",
    "dense_feat = ['bnspt', 'timestamp_0', 'timestamp_1', 'objam'], \n",
    "sparse_feat = ['chid', 'bnsfg', 'iterm', 'mcc', 'scity'], \n",
    "USE_CHID = True\n",
    "\n",
    "sparse_dense_setting_generator = GenerateSparseDenseSetting(\n",
    "    category_cols=category_cols, \n",
    "    sparse_feat=sparse_feat, \n",
    "    numeric_cols=numeric_cols, \n",
    "    dense_feat=dense_feat, \n",
    "    USE_CHID=USE_CHID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PB_0 = PipelineBuilder()\n",
    "chids = PB_0.add(load_chids, output_alias = 'chids')(chid_file = chid_file)\n",
    "\n",
    "sampled_chids = PB_0.add(\n",
    "    sample_chids, \n",
    "    output_alias = 'sampled_chids', \n",
    "    result_dir = os.path.join(sample_path,'sampled_chids.npy')\n",
    ")(chids, n_sample = 50)\n",
    "PB_0.view(summary = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PB_0.view_dependency('sample_chids', summary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PB = PipelineBuilder()\n",
    "chid_to_nid_map = PB.add(build_chid_to_nid_map, output_alias = 'chid_to_nid_map')(\n",
    "    sampled_chids\n",
    ")\n",
    "df_cdtx = PB.add(load_cdtx, output_alias = 'df_cdtx')(\n",
    "    sampled_chids, \n",
    "    cdtx_file = cdtx_file\n",
    ")\n",
    "df_cdtx = PB.add(convert_uid_to_nid, output_alias = 'df_cdtx')(\n",
    "    df_cdtx, \n",
    "    chid_to_nid_map\n",
    ")\n",
    "df_cdtx = PB.add(add_month, \n",
    "                 output_alias = 'df_cdtx', \n",
    "                 result_dir = os.path.join(tmp_path, 'df_cdtx.feather')\n",
    "                )(df_cdtx)\n",
    "\n",
    "df_full_y_sum = PB.add(\n",
    "    make_chid_x_month_table, \n",
    "    output_alias = 'df_full_y_sum'\n",
    ")(\n",
    "    df_cdtx\n",
    ")\n",
    "\n",
    "df_cdtx_monthly_objam = PB.add(calculate_monthly_target, output_alias = 'df_cdtx_monthly_objam')(\n",
    "    df_cdtx\n",
    ")\n",
    "\n",
    "df_full_y_sum = PB.add(merge_with_another_table, output_alias = 'df_full_y_sum')(\n",
    "    df_full_y_sum, \n",
    "    df_cdtx_monthly_objam, \n",
    "    join_method='left'\n",
    ")\n",
    "\n",
    "df_cust_f = PB.add(load_cust_f, output_alias = 'df_cust_f')(\n",
    "    sampled_chids, \n",
    "    cust_f_file = cust_f_file\n",
    ")\n",
    "\n",
    "df_cust_f = PB.add(\n",
    "    convert_uid_to_nid, \n",
    "    output_alias = 'df_cust_f', \n",
    "    result_dir = os.path.join(tmp_path, 'df_cust_f.feather')\n",
    ")(\n",
    "    df_cust_f, \n",
    "    chid_to_nid_map\n",
    ")\n",
    "\n",
    "df_full_y_sum = PB.add(merge_with_another_table, output_alias = 'df_full_y_sum')(\n",
    "    df_full_y_sum, df_cust_f, join_method='inner')\n",
    "\n",
    "df_full_y_sum = PB.add(add_mean_of_previous_two_months, output_alias = 'df_full_y_sum')(\n",
    "    df_full_y_sum)\n",
    "\n",
    "\n",
    "\n",
    "df_full_y_sum = PB.add(cast_time_column_to_np_datatime64, output_alias = 'df_full_y_sum')(\n",
    "    df_full_y_sum, time_column = 'data_dt')\n",
    "\n",
    "df_cdtx = PB.add(cast_time_column_to_np_datatime64, output_alias = 'df_cdtx')(\n",
    "    df_cdtx, time_column = 'csmdt')\n",
    "\n",
    "\n",
    "df_cdtx = PB.add(add_duration_since_20180101, output_alias = 'df_cdtx')(\n",
    "    df_cdtx, time_column = 'csmdt', result_column='timestamp_1')\n",
    "\n",
    "\n",
    "df_cdtx = PB.add(add_duration_since_last_trans, output_alias = 'df_cdtx')(\n",
    "    df_cdtx, time_column = 'csmdt', result_column='timestamp_0')\n",
    "\n",
    "\n",
    "df_input, feature_map = PB.add(\n",
    "    extract_feature_cols_and_encode_categoricals, \n",
    "    n_out = 2, \n",
    "    output_alias = ['df_input', 'feature_map'], \n",
    "    result_dir=[\n",
    "                os.path.join(tmp_path, 'df_input.feather'),\n",
    "                os.path.join(tmp_path, 'feature_map.npy')\n",
    "            ]\n",
    ")(\n",
    "    df_cdtx, \n",
    "    numeric_cols=['bnspt', 'timestamp_0', 'timestamp_1', 'objam'],\n",
    "    category_cols=['chid', 'bnsfg', 'iterm', 'mcc', 'scity']\n",
    ")\n",
    "\n",
    "df_feat_input, cust_feature_map = PB.add(\n",
    "    extract_feature_cols_and_encode_categoricals, \n",
    "    n_out = 2, \n",
    "    output_alias = ['df_feat_input', 'cust_feature_map'], \n",
    "    result_dir=[\n",
    "                os.path.join(tmp_path, 'df_feat_input.1.feather'),\n",
    "                os.path.join(tmp_path, 'cust_feature_map.npy')\n",
    "            ]\n",
    ")(\n",
    "    df_cust_f, \n",
    "    numeric_cols=['slam', 'first_mob', 'constant_change', 'sum_l2_ind',\n",
    "                  'sum_u2_ind', 'constant_l2_ind', 'constant_u4_ind',\n",
    "                  'growth_rate', 'monotone_down', 'monotone_up', 'data_dt'],\n",
    "    category_cols=['chid', 'masts', 'educd', 'trdtp', 'poscd']\n",
    ")\n",
    "\n",
    "df_feat_input = PB.add(cast_time_column_to_np_datatime64, output_alias = 'df_feat_input')(\n",
    "    df_feat_input, time_column = 'data_dt')\n",
    "\n",
    "df_feat_input = PB.add(\n",
    "    add_duration_since_20180101, \n",
    "    output_alias = 'df_feat_input', \n",
    "    result_dir = os.path.join(tmp_path, 'df_feat_input.2.feather')\n",
    ")(\n",
    "    df_feat_input, time_column = 'data_dt', result_column='timestamp')\n",
    "\n",
    "df_y = PB.add(extract_target_columns, output_alias = 'df_y')(\n",
    "    df_full_y_sum,\n",
    "    target_cols=['chid', 'data_dt', 'objam_sum', 'objam_mean', 'trans_count', 'objam_mean_M3'],  # 'shop_count'\n",
    ")\n",
    "df_y = PB.add(\n",
    "    add_duration_since_20180101, \n",
    "    output_alias = 'df_y', \n",
    "    result_dir = os.path.join(tmp_path, 'df_y.feather')\n",
    ")(\n",
    "    df_y, time_column = 'data_dt', result_column='timestamp')\n",
    "\n",
    "PB.view(summary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_feature_map.get(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PB.view_dependency('calculate_monthly_target', summary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PB_1 = PipelineBuilder()\n",
    "# split_data\n",
    "# add_objam_mean_M3_diff_as_new_target\n",
    "# extract_x_f_y_columns\n",
    "\n",
    "x_train, x_test, f_train, f_test, y_train, y_test = PB_1.add(\n",
    "    split_data, \n",
    "    n_out = 6,\n",
    "    output_alias = ['x_train', 'x_test', 'f_train', 'f_test', 'y_train', 'y_test'],\n",
    "    result_dir=[\n",
    "                os.path.join(tmp_path, 'x_train.npy'),\n",
    "                os.path.join(tmp_path, 'x_test.npy'),\n",
    "                os.path.join(tmp_path, 'f_train.npy'),\n",
    "                os.path.join(tmp_path, 'f_test.npy'),\n",
    "                os.path.join(tmp_path, 'y_train.npy'),\n",
    "                os.path.join(tmp_path, 'y_test.npy')\n",
    "            ]\n",
    ")(df_input, df_feat_input, df_y, window_size = window_size, test_size = test_size)\n",
    "\n",
    "\n",
    "y_train, y_test, y_columns = PB_1.add(\n",
    "    add_objam_mean_M3_diff_as_new_target, \n",
    "    n_out = 3,\n",
    "    output_alias = ['y_train', 'y_test', 'y_columns'],\n",
    "    result_dir = [\n",
    "        os.path.join(tmp_path, 'y_train.npy'),\n",
    "        os.path.join(tmp_path, 'y_test.npy'),\n",
    "        os.path.join(tmp_path, 'y_columns.npy')\n",
    "    ]\n",
    ")(df_y, y_train, y_test)\n",
    "\n",
    "columns = PB_1.add(extract_x_f_y_columns, output_alias = 'columns')(\n",
    "    df_input, df_feat_input, y_columns\n",
    ")\n",
    "\n",
    "\n",
    "'''\n",
    "for output in [x_train, x_test, f_train, f_test, y_train, y_test, columns, feature_map, cust_feature_map, chid_to_nid_map]:\n",
    "    output.get()\n",
    "'''\n",
    "PB_1.view(summary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PB_2 = PB_1#PipelineBuilder()\n",
    "\n",
    "sparse_dims, sparse_index, dense_dims, dense_index = PB_2.add(\n",
    "    sparse_dense_setting_generator.process,\n",
    "    method_alias = 'generate_sparse_dense_setting',\n",
    "    n_out = 4, \n",
    "    output_alias = ['sparse_dims', 'sparse_index', 'dense_dims', 'dense_index']\n",
    ")(\n",
    "    feature_map, chid_to_nid_map\n",
    ")\n",
    "\n",
    "x_train_sparse, x_train_dense, x_test_sparse, x_test_dense = PB_2.add(\n",
    "    ProcessX.process,\n",
    "    method_alias = 'ProcessX.process',\n",
    "    n_out = 4, \n",
    "    output_alias = ['x_train_sparse', 'x_train_dense', 'x_test_sparse', 'x_test_dense']\n",
    ")(\n",
    "    x_train, x_test, sparse_index, dense_index\n",
    ")\n",
    "\n",
    "train_objmean, train_tscnt, train_label_0, test_objmean, test_tscnt, test_label_0 = PB_2.add(\n",
    "    ProcessY.process,\n",
    "    method_alias = 'ProcessY.process',\n",
    "    n_out = 6, \n",
    "    output_alias = ['train_objmean', 'train_tscnt', 'train_label_0', 'test_objmean', 'test_tscnt', 'test_label_0']\n",
    ")(\n",
    "    y_train, y_test, columns\n",
    ")\n",
    "\n",
    "train_dataset = PB_2.add(\n",
    "    build_TensorDataset,\n",
    "    output_alias = 'train_dataset'\n",
    ")(\n",
    "    x_train_dense, x_train_sparse, train_objmean, train_tscnt, train_label_0\n",
    ")\n",
    "    \n",
    "test_dataset = PB_2.add(\n",
    "    build_TensorDataset,\n",
    "    output_alias = 'test_dataset'\n",
    ")(\n",
    "    x_test_dense, x_test_sparse, test_objmean, test_tscnt, test_label_0\n",
    ")\n",
    "PB_2.view(summary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PB_2.view_dependency('x_train', 'y_train', 'x_test', 'y_test', 'columns', summary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.run(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
