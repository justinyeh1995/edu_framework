{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from time import time\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_path = './data'\n",
    "\n",
    "chid_file = 'sample_chid.txt'\n",
    "chid_dict_file = 'sample_idx_map.npy'\n",
    "cdtx_file = 'sample_zip_if_cca_cdtx0001_hist.csv'\n",
    "cust_f_file = 'sample_zip_if_cca_cust_f.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,) 50000 (6654938, 10) (1176172, 32)\n"
     ]
    }
   ],
   "source": [
    "chid_array = np.loadtxt(os.path.join(sample_path, chid_file), dtype=np.str)\n",
    "chid_dict = np.load(os.path.join(sample_path, chid_dict_file), allow_pickle=True).tolist()\n",
    "df_cdtx = pd.read_csv(os.path.join(sample_path, cdtx_file)) # 交易記錄檔\n",
    "df_cust_f = pd.read_csv(os.path.join(sample_path, cust_f_file)) # user feature\n",
    "df_cust_f.drop_duplicates(ignore_index=True, inplace=True)\n",
    "\n",
    "print(chid_array.shape, len(chid_dict), df_cdtx.shape, df_cust_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cdtx = df_cdtx[df_cdtx.chid.isin(chid_array)].copy()\n",
    "df_cust_f = df_cust_f[df_cust_f.chid.isin(chid_array)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 50000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_ym</th>\n",
       "      <th>monin</th>\n",
       "      <th>wrky</th>\n",
       "      <th>first_mob</th>\n",
       "      <th>data_dt</th>\n",
       "      <th>masts</th>\n",
       "      <th>educd</th>\n",
       "      <th>naty</th>\n",
       "      <th>trdtp</th>\n",
       "      <th>poscd</th>\n",
       "      <th>...</th>\n",
       "      <th>constant_u2_ind</th>\n",
       "      <th>constant_u3_ind</th>\n",
       "      <th>constant_u4_ind</th>\n",
       "      <th>constant_l2_ind</th>\n",
       "      <th>constant_l3_ind</th>\n",
       "      <th>constant_l4_ind</th>\n",
       "      <th>constant_change</th>\n",
       "      <th>growth_rate</th>\n",
       "      <th>monotone_up</th>\n",
       "      <th>monotone_down</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15475</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49572</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23964</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49830</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41574</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       data_ym  monin  wrky  first_mob  data_dt  masts  educd  naty  trdtp  \\\n",
       "chid                                                                         \n",
       "15475       11     11    11         11       11     11     11    11     11   \n",
       "49572       11     11    11         11       11     11     11    11     11   \n",
       "23964       11     11    11         11       11     11     11    11     11   \n",
       "49830       11     11    11         11       11     11     11    11     11   \n",
       "41574       11     11    11         11       11     11     11    11     11   \n",
       "\n",
       "       poscd  ...  constant_u2_ind  constant_u3_ind  constant_u4_ind  \\\n",
       "chid          ...                                                      \n",
       "15475     11  ...               11               11               11   \n",
       "49572     11  ...               11               11               11   \n",
       "23964     11  ...               11               11               11   \n",
       "49830     11  ...               11               11               11   \n",
       "41574     11  ...               11               11               11   \n",
       "\n",
       "       constant_l2_ind  constant_l3_ind  constant_l4_ind  constant_change  \\\n",
       "chid                                                                        \n",
       "15475               11               11               11               11   \n",
       "49572               11               11               11               11   \n",
       "23964               11               11               11               11   \n",
       "49830               11               11               11               11   \n",
       "41574               11               11               11               11   \n",
       "\n",
       "       growth_rate  monotone_up  monotone_down  \n",
       "chid                                            \n",
       "15475           11           11             11  \n",
       "49572           11           11             11  \n",
       "23964           11           11             11  \n",
       "49830           11           11             11  \n",
       "41574           11           11             11  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cdtx.chid = df_cdtx.chid.map(chid_dict)\n",
    "df_cust_f.chid = df_cust_f.chid.map(chid_dict)\n",
    "\n",
    "print(len(df_cdtx.chid.unique()), len(df_cust_f.chid.unique()))\n",
    "df_cust_f.groupby('chid').count().sort_values(by='data_ym').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bnsfg</th>\n",
       "      <th>bnspt</th>\n",
       "      <th>chid</th>\n",
       "      <th>csmdt</th>\n",
       "      <th>iterm</th>\n",
       "      <th>mcc</th>\n",
       "      <th>objam</th>\n",
       "      <th>scity</th>\n",
       "      <th>tcode</th>\n",
       "      <th>hcefg</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>8054</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>5411</td>\n",
       "      <td>151</td>\n",
       "      <td>TAOYUAN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>8054</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>5411</td>\n",
       "      <td>146</td>\n",
       "      <td>TAOYUAN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  bnsfg  bnspt  chid       csmdt  iterm   mcc  objam    scity  tcode hcefg  \\\n",
       "0     N      0  8054  2018-01-01      0  5411    151  TAOYUAN      5   NaN   \n",
       "1     N      0  8054  2018-01-01      0  5411    146  TAOYUAN      5   NaN   \n",
       "\n",
       "        month  \n",
       "0  2018-01-01  \n",
       "1  2018-01-01  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cdtx['month'] = df_cdtx.csmdt.apply(lambda x: x[:-3]+'-01')\n",
    "df_cdtx.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600000, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 填滿後12個月\n",
    "\n",
    "list_chid = sorted(df_cust_f.chid.unique())\n",
    "list_month = sorted(df_cust_f.data_dt.unique())[12:]\n",
    "\n",
    "df_full_y_sum = pd.DataFrame({\n",
    "    'chid': list_chid*len(list_month),\n",
    "}).sort_values(by='chid', ignore_index=True)\n",
    "df_full_y_sum['data_dt'] = list_month*len(list_chid)\n",
    "\n",
    "df_full_y_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chid</th>\n",
       "      <th>data_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599995</th>\n",
       "      <td>49999</td>\n",
       "      <td>2019-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599996</th>\n",
       "      <td>49999</td>\n",
       "      <td>2019-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599997</th>\n",
       "      <td>49999</td>\n",
       "      <td>2019-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599998</th>\n",
       "      <td>49999</td>\n",
       "      <td>2019-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599999</th>\n",
       "      <td>49999</td>\n",
       "      <td>2019-12-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         chid     data_dt\n",
       "0           0  2019-01-01\n",
       "1           0  2019-02-01\n",
       "2           0  2019-03-01\n",
       "3           0  2019-04-01\n",
       "4           0  2019-05-01\n",
       "...       ...         ...\n",
       "599995  49999  2019-08-01\n",
       "599996  49999  2019-09-01\n",
       "599997  49999  2019-10-01\n",
       "599998  49999  2019-11-01\n",
       "599999  49999  2019-12-01\n",
       "\n",
       "[600000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_y_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600000, 32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## join feature\n",
    "category_cols = ['masts', 'educd', 'naty', 'trdtp', 'poscd', 'cuorg']\n",
    "\n",
    "numeric_cols = sorted(set(df_cust_f.columns) - set(category_cols) - set(['chid', 'data_ym', 'data_dt']), \n",
    "                      key=list(df_cust_f.columns).index)\n",
    "\n",
    "df_full_y_sum = df_full_y_sum.merge(df_cust_f[['chid', 'data_ym'] + category_cols + numeric_cols], \n",
    "                                    how='left', \n",
    "                                    left_on=['chid', 'data_dt'], \n",
    "                                    right_on=['chid', 'data_ym'])\n",
    "\n",
    "#df_full_y_sum.dropna(thresh=len(numeric_cols+category_cols), inplace=True)\n",
    "\n",
    "## fill na value, numerical: 0, category: '-1'\n",
    "values = dict()\n",
    "\n",
    "for col in numeric_cols:\n",
    "    values[col] = 0\n",
    "    \n",
    "for col in category_cols:\n",
    "    values[col] = '-1'\n",
    "    \n",
    "df_full_y_sum.fillna(value=values, inplace=True)\n",
    "df_full_y_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 取得整個月的 objam \n",
    "temp_cdtx = df_cdtx.groupby(['chid', 'month']).sum()\n",
    "df_cdtx_objam = pd.DataFrame(list(map(list, temp_cdtx.index)), columns=['chid', 'data_dt'])\n",
    "df_cdtx_objam['objam'] = np.ma.log(temp_cdtx.objam.values).filled(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600000, 33)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## join objam\n",
    "\n",
    "df_full_y_sum = df_full_y_sum.merge(df_cdtx_objam, \n",
    "                                    how='left', \n",
    "                                    left_on=['chid', 'data_dt'], \n",
    "                                    right_on=['chid', 'data_dt']).fillna(0)\n",
    "\n",
    "df_full_y_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600000, 33)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chid</th>\n",
       "      <th>data_dt</th>\n",
       "      <th>data_ym</th>\n",
       "      <th>masts</th>\n",
       "      <th>educd</th>\n",
       "      <th>naty</th>\n",
       "      <th>trdtp</th>\n",
       "      <th>poscd</th>\n",
       "      <th>cuorg</th>\n",
       "      <th>monin</th>\n",
       "      <th>...</th>\n",
       "      <th>constant_u3_ind</th>\n",
       "      <th>constant_u4_ind</th>\n",
       "      <th>constant_l2_ind</th>\n",
       "      <th>constant_l3_ind</th>\n",
       "      <th>constant_l4_ind</th>\n",
       "      <th>constant_change</th>\n",
       "      <th>growth_rate</th>\n",
       "      <th>monotone_up</th>\n",
       "      <th>monotone_down</th>\n",
       "      <th>objam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>173472.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>173472.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   chid     data_dt     data_ym  masts  educd  naty  trdtp  poscd  cuorg  \\\n",
       "0     0  2019-01-01  2019-01-01      3      5     2     23      2      8   \n",
       "1     0  2019-02-01  2019-02-01      3      5     2     23      2      8   \n",
       "\n",
       "      monin  ...  constant_u3_ind  constant_u4_ind  constant_l2_ind  \\\n",
       "0  173472.0  ...              0.0              0.0              1.0   \n",
       "1  173472.0  ...              0.0              0.0              0.0   \n",
       "\n",
       "   constant_l3_ind  constant_l4_ind  constant_change  growth_rate  \\\n",
       "0              0.0              0.0              0.0          0.8   \n",
       "1              0.0              0.0              0.0          0.8   \n",
       "\n",
       "   monotone_up  monotone_down  objam  \n",
       "0          0.0            3.0    0.0  \n",
       "1          0.0            5.0    0.0  \n",
       "\n",
       "[2 rows x 33 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper = {col: {value: index for index, value in enumerate(sorted(df_full_y_sum[col].unique()))} \n",
    "          for col in category_cols}\n",
    "\n",
    "df_full_y_sum[category_cols] = df_full_y_sum[category_cols].apply(lambda x: x.map(mapper[x.name]))\n",
    "\n",
    "print(df_full_y_sum.shape)\n",
    "df_full_y_sum.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['data_dt'] \n",
      "\n",
      "7 ['chid', 'masts', 'educd', 'naty', 'trdtp', 'poscd', 'cuorg'] \n",
      "\n",
      "24 ['monin', 'wrky', 'first_mob', 'cycam', 'slam', 'sum_area_c', 'sum_u2_ind', 'sum_u3_ind', 'sum_u4_ind', 'sum_l2_ind', 'sum_l3_ind', 'sum_l4_ind', 'constant_area_c', 'constant_u2_ind', 'constant_u3_ind', 'constant_u4_ind', 'constant_l2_ind', 'constant_l3_ind', 'constant_l4_ind', 'constant_change', 'growth_rate', 'monotone_up', 'monotone_down', 'objam']\n"
     ]
    }
   ],
   "source": [
    "df_full_y_sum.drop(columns=['data_ym'], inplace=True)\n",
    "\n",
    "ignore_cols = ['data_dt']\n",
    "category_cols = ['chid'] + category_cols\n",
    "numeric_cols = sorted(set(df_full_y_sum.columns) - set(category_cols) - set(ignore_cols), \n",
    "                      key=list(df_full_y_sum.columns).index)\n",
    "\n",
    "print(len(ignore_cols), ignore_cols, '\\n')\n",
    "print(len(category_cols), category_cols, '\\n')\n",
    "print(len(numeric_cols), numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(df, numeric_cols=[], category_cols=[], test_size=0.166, x_minmax=None, y_minmax=None):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = [], [], [], []\n",
    "    df = df[category_cols + numeric_cols].copy()\n",
    "            \n",
    "    for i in tqdm(sorted(df.chid.unique())):\n",
    "        data = df[df.chid == i]\n",
    "        last = data.shape[0] - 1\n",
    "        test_num = round(data.shape[0]*test_size)            \n",
    "\n",
    "        x_train.append(data.iloc[0:last - test_num])\n",
    "        y_train.append(data.iloc[1:last - test_num + 1, [-1]])\n",
    "\n",
    "        x_test.append(data.iloc[last - test_num: last])\n",
    "        y_test.append(data.iloc[last - test_num + 1: last + 1, [-1]])\n",
    "\n",
    "    x_train = pd.concat(x_train)\n",
    "    y_train = pd.concat(y_train)\n",
    "    \n",
    "    x_test = pd.concat(x_test)\n",
    "    y_test = pd.concat(y_test)\n",
    "    \n",
    "    if x_minmax or y_minmax:\n",
    "        scaler_dcit = dict()\n",
    "    \n",
    "    if x_minmax:\n",
    "        x_scaler = MinMaxScaler(feature_range=x_minmax)\n",
    "        x_train[numeric_cols] = x_scaler.fit_transform(x_train[numeric_cols])\n",
    "        x_test[numeric_cols] = x_scaler.transform(x_test[numeric_cols]) \n",
    "        \n",
    "        scaler_dcit['x'] = x_scaler\n",
    "    if y_minmax:\n",
    "        y_scaler = MinMaxScaler(feature_range=y_minmax)  \n",
    "        y_train = y_scaler.fit_transform(y_train)\n",
    "        y_test = y_scaler.transform(y_test)    \n",
    "        \n",
    "        scaler_dict['y'] = y_scaler\n",
    "         \n",
    "    if x_minmax or y_minmax:\n",
    "        return x_train, x_test, y_train, y_test, scaler_dcit\n",
    "    else:\n",
    "        return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec082acfcd644a1be8ad741732c6a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train:9, test:2\n",
      "(450000, 31) (450000, 1) (100000, 31) (100000, 1)\n"
     ]
    }
   ],
   "source": [
    "x_minmax, y_minmax = (0,1), None\n",
    "\n",
    "if x_minmax or y_minmax:\n",
    "    x_train, x_test, y_train, y_test, scaler_dcit = data_split(df_full_y_sum, numeric_cols, category_cols, \n",
    "                                                               x_minmax=x_minmax, y_minmax=y_minmax, test_size=0.166)\n",
    "else:\n",
    "    x_train, x_test, y_train, y_test = data_split(df_full_y_sum, numeric_cols, category_cols, test_size=0.166)    \n",
    "\n",
    "num_chid = len(set(df_full_y_sum.chid))\n",
    "print('train:{}, test:{}'.format(x_train.shape[0]//num_chid, x_test.shape[0]//num_chid))\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.621522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.918493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>13.009936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        objam\n",
       "10  10.621522\n",
       "11  12.918493\n",
       "22   0.000000\n",
       "23   0.000000\n",
       "34  13.009936"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_index(x, feature_cols):\n",
    "    feature_idx = {}\n",
    "    x_cols = list(x.columns)\n",
    "    for i in feature_cols:\n",
    "        feature_idx[i] = x_cols.index(i)\n",
    "        \n",
    "    return feature_idx\n",
    "\n",
    "def Linear_block(in_dim, out_dim):\n",
    "    block = torch.nn.Sequential(torch.nn.Linear(in_dim, out_dim),\n",
    "                                torch.nn.ReLU())\n",
    "    return block\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, category_cols, category_dims, ori_dim, layer_dims, embedding_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.out_dims = [ori_dim, *layer_dims]\n",
    "        Linear_blokcs = [Linear_block(in_dim, out_dim)\n",
    "                         for in_dim, out_dim in zip(self.out_dims, self.out_dims[1:])]\n",
    "        self.model = torch.nn.Sequential(*Linear_blokcs)\n",
    "        self.embedding_dict = torch.nn.ModuleDict({category_col:torch.nn.Embedding(category_dim,\n",
    "                                                                                   embedding_dim)\n",
    "                                                   if category_col != 'chid' else torch.nn.Embedding(category_dim,\n",
    "                                                                                   512)\n",
    "                                                   for category_col, category_dim in zip(category_cols,category_dims)})\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, x, category_cols, category_dict, numeric_dict):\n",
    "    \n",
    "        category_embeddings = [self.embedding_dict[item[0]](x[:,item[1]].long()) for item in category_dict.items()]\n",
    "        category_embeddings = torch.cat(category_embeddings, -1)\n",
    "        \n",
    "        numeric_idx = torch.Tensor(list(numeric_dict.values())).long()\n",
    "        \n",
    "        x = torch.cat([category_embeddings, x[:,numeric_idx]], -1)\n",
    "        \n",
    "        x = self.model(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['data_dt'] \n",
      "\n",
      "7 ['chid', 'masts', 'educd', 'naty', 'trdtp', 'poscd', 'cuorg'] \n",
      "\n",
      "24 ['monin', 'wrky', 'first_mob', 'cycam', 'slam', 'sum_area_c', 'sum_u2_ind', 'sum_u3_ind', 'sum_u4_ind', 'sum_l2_ind', 'sum_l3_ind', 'sum_l4_ind', 'constant_area_c', 'constant_u2_ind', 'constant_u3_ind', 'constant_u4_ind', 'constant_l2_ind', 'constant_l3_ind', 'constant_l4_ind', 'constant_change', 'growth_rate', 'monotone_up', 'monotone_down', 'objam']\n"
     ]
    }
   ],
   "source": [
    "print(len(ignore_cols), ignore_cols, '\\n')\n",
    "print(len(category_cols), category_cols, '\\n')\n",
    "print(len(numeric_cols), numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_cols = category_cols[:]\n",
    "numeric_cols = numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dims = [df_full_y_sum[feat].nunique() for feat in category_cols]\n",
    "\n",
    "category_dict = feature_index(x_train, category_cols)\n",
    "numeric_dict = feature_index(x_train, numeric_cols)\n",
    "embedding_size = 64\n",
    "\n",
    "layer_dims = [256, 128, 1]\n",
    "input_dim = (len(category_dict)-1)*embedding_size + len(numeric_dict) + 512\n",
    "\n",
    "epochs = 400\n",
    "batch_size = 2048\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(torch.from_numpy(x_train.to_numpy()),\n",
    "                              torch.from_numpy(y_train.to_numpy()))\n",
    "train_loader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "test_dataset = TensorDataset(torch.from_numpy(x_test.to_numpy()),\n",
    "                              torch.from_numpy(y_test.to_numpy()))\n",
    "test_loader = DataLoader(dataset=test_dataset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (model): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=920, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=1, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (embedding_dict): ModuleDict(\n",
       "    (chid): Embedding(50000, 512)\n",
       "    (masts): Embedding(4, 64)\n",
       "    (educd): Embedding(7, 64)\n",
       "    (naty): Embedding(3, 64)\n",
       "    (trdtp): Embedding(28, 64)\n",
       "    (poscd): Embedding(10, 64)\n",
       "    (cuorg): Embedding(31, 64)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = MLP(category_cols, category_dims, input_dim,layer_dims, embedding_size).to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_NODE2VEC = True\n",
    "if USE_NODE2VEC:\n",
    "    node2vec_emb = np.load(os.path.join('../Embedding/GCNEncoder_0126.npy'), allow_pickle=True)\n",
    "    node2vec_emb = torch.from_numpy(node2vec_emb[:50000])\n",
    "    model.embedding_dict['chid'].weight.data.copy_(node2vec_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHID_FINETUNING = True\n",
    "\n",
    "if CHID_FINETUNING:\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    optimizer_parameters = [{\"params\": [p for n, p in param_optimizer]}]  \n",
    "    #model.embedding_dict['chid'].weight.requires_grad = True\n",
    "else:\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    optimizer_parameters = [{\"params\": [p for n, p in param_optimizer if not 'embedding_dict.chid.weight' == n]}]\n",
    "    #model.embedding_dict['chid'].weight.requires_grad = False\n",
    "    \n",
    "optimizer = torch.optim.Adam(optimizer_parameters, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67abd40d07a648a3970a1eee702654c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "train loss:379507,test loss:404373\n",
      "train MAE(mean):50198,test MAE(mean):59169\n",
      "train MAE(median):9008, test MAE(median):10842\n",
      "\tBetter!\n",
      "epoch:1\n",
      "train loss:376817,test loss:404946\n",
      "train MAE(mean):49868,test MAE(mean):57099\n",
      "train MAE(median):8936, test MAE(median):9990\n",
      "epoch:2\n",
      "train loss:377736,test loss:403823\n",
      "train MAE(mean):49108,test MAE(mean):58054\n",
      "train MAE(median):8759, test MAE(median):11065\n",
      "\tBetter!\n",
      "epoch:3\n",
      "train loss:376305,test loss:404406\n",
      "train MAE(mean):49073,test MAE(mean):57342\n",
      "train MAE(median):8756, test MAE(median):10518\n",
      "epoch:4\n",
      "train loss:373926,test loss:408343\n",
      "train MAE(mean):48782,test MAE(mean):57729\n",
      "train MAE(median):8696, test MAE(median):9487\n",
      "epoch:5\n",
      "train loss:375683,test loss:404680\n",
      "train MAE(mean):48964,test MAE(mean):58152\n",
      "train MAE(median):8690, test MAE(median):10961\n",
      "epoch:6\n",
      "train loss:375376,test loss:405352\n",
      "train MAE(mean):48900,test MAE(mean):57727\n",
      "train MAE(median):8654, test MAE(median):10501\n",
      "epoch:7\n",
      "train loss:376012,test loss:406782\n",
      "train MAE(mean):48903,test MAE(mean):58576\n",
      "train MAE(median):8594, test MAE(median):10749\n",
      "epoch:8\n",
      "train loss:375922,test loss:405507\n",
      "train MAE(mean):49009,test MAE(mean):57909\n",
      "train MAE(median):8608, test MAE(median):10293\n",
      "epoch:9\n",
      "train loss:374149,test loss:411290\n",
      "train MAE(mean):49202,test MAE(mean):60149\n",
      "train MAE(median):8603, test MAE(median):9709\n",
      "epoch:10\n",
      "train loss:375030,test loss:405451\n",
      "train MAE(mean):49346,test MAE(mean):58911\n",
      "train MAE(median):8614, test MAE(median):10441\n",
      "epoch:11\n",
      "train loss:373131,test loss:408260\n",
      "train MAE(mean):48967,test MAE(mean):59405\n",
      "train MAE(median):8501, test MAE(median):10913\n",
      "epoch:12\n",
      "train loss:383265,test loss:406863\n",
      "train MAE(mean):49106,test MAE(mean):58982\n",
      "train MAE(median):8579, test MAE(median):10266\n",
      "epoch:13\n",
      "train loss:370860,test loss:406159\n",
      "train MAE(mean):47842,test MAE(mean):62477\n",
      "train MAE(median):8337, test MAE(median):12239\n",
      "epoch:14\n",
      "train loss:371109,test loss:407101\n",
      "train MAE(mean):47382,test MAE(mean):64691\n",
      "train MAE(median):8286, test MAE(median):13404\n",
      "epoch:15\n",
      "train loss:369219,test loss:407575\n",
      "train MAE(mean):47150,test MAE(mean):60219\n",
      "train MAE(median):8209, test MAE(median):11384\n",
      "epoch:16\n",
      "train loss:373813,test loss:406503\n",
      "train MAE(mean):46560,test MAE(mean):61333\n",
      "train MAE(median):8014, test MAE(median):11935\n",
      "epoch:17\n",
      "train loss:364608,test loss:413819\n",
      "train MAE(mean):46275,test MAE(mean):65238\n",
      "train MAE(median):7939, test MAE(median):12888\n",
      "epoch:18\n",
      "train loss:367407,test loss:407254\n",
      "train MAE(mean):46208,test MAE(mean):64568\n",
      "train MAE(median):7866, test MAE(median):12936\n",
      "epoch:19\n",
      "train loss:367598,test loss:407551\n",
      "train MAE(mean):46196,test MAE(mean):60499\n",
      "train MAE(median):7855, test MAE(median):11024\n",
      "epoch:20\n",
      "train loss:367844,test loss:406701\n",
      "train MAE(mean):45366,test MAE(mean):64404\n",
      "train MAE(median):7627, test MAE(median):13503\n",
      "epoch:21\n",
      "train loss:365217,test loss:407842\n",
      "train MAE(mean):45042,test MAE(mean):62246\n",
      "train MAE(median):7504, test MAE(median):12534\n",
      "epoch:22\n",
      "train loss:366837,test loss:407069\n",
      "train MAE(mean):44628,test MAE(mean):62393\n",
      "train MAE(median):7394, test MAE(median):12477\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = 20\n",
    "\n",
    "best_loss = 1e10\n",
    "early_cnt = 0\n",
    "RMSE = []\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    \n",
    "    train_loss = 0\n",
    "    test_loss = 0\n",
    "    train_output = np.array([])\n",
    "    train_y = np.array([])\n",
    "    test_output = np.array([])\n",
    "    test_y = np.array([])\n",
    "    \n",
    "    for x , y in train_loader:\n",
    "        x, y = x.float().to(device), y.float().to(device)\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(x, category_cols, category_dict, numeric_dict)\n",
    "\n",
    "        loss = criterion(output, y)\n",
    "        train_loss += loss.item()\n",
    "        train_output = np.concatenate([train_output,output.cpu().detach().numpy().reshape(-1)])\n",
    "        train_y = np.concatenate([train_y,y.cpu().detach().numpy().reshape(-1)])\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    for x , y in test_loader:\n",
    "        x, y = x.float().to(device), y.float().to(device)\n",
    "        model.eval()        \n",
    "        output = model(x, category_cols, category_dict, numeric_dict)\n",
    "        loss = criterion(output, y)\n",
    "        test_loss += loss.item()\n",
    "        test_output = np.concatenate([test_output,output.cpu().detach().numpy().reshape(-1)])\n",
    "        test_y = np.concatenate([test_y,y.cpu().detach().numpy().reshape(-1)])\n",
    "    \n",
    "    #train_loss = np.sqrt(train_loss/len(train_loader))\n",
    "    #test_loss = np.sqrt(test_loss/len(test_loader))\n",
    "    \n",
    "    train_output, train_y = np.e**train_output, np.e**train_y\n",
    "    train_RMSE = mean_squared_error(train_output, train_y, squared=False)\n",
    "    train_mean = mean_absolute_error(train_output, train_y)\n",
    "    train_median = median_absolute_error(train_output, train_y)\n",
    "    \n",
    "    test_output, test_y = np.e**test_output, np.e**test_y\n",
    "    test_RMSE = mean_squared_error(test_output, test_y, squared=False)\n",
    "    test_mean = mean_absolute_error(test_output, test_y)\n",
    "    test_median = median_absolute_error(test_output, test_y)\n",
    "    \n",
    "    print(f'epoch:{epoch}\\ntrain loss:{train_RMSE:.0f},test loss:{test_RMSE:.0f}\\ntrain MAE(mean):{train_mean:.0f},test MAE(mean):{test_mean:.0f}\\ntrain MAE(median):{train_median:.0f}, test MAE(median):{test_median:.0f}')\n",
    "    \n",
    "    if test_RMSE <= best_loss:\n",
    "        best_model_params = copy.deepcopy(model.state_dict())\n",
    "        best_loss = test_RMSE\n",
    "        print('\\tBetter!')\n",
    "        early_cnt = 0\n",
    "    else:\n",
    "        early_cnt += 1\n",
    "    \n",
    "    if early_cnt >= early_stop:\n",
    "        break\n",
    "\n",
    "model.load_state_dict(best_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output = np.array([])\n",
    "train_y = np.array([])\n",
    "test_output = np.array([])\n",
    "test_y = np.array([])\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for x , y in train_loader:\n",
    "    x, y = x.float().to(device), y.float().to(device)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    output = model(x, category_cols, category_dict, numeric_dict)\n",
    "    train_output = np.concatenate([train_output,output.cpu().detach().numpy().reshape(-1)])\n",
    "    train_y = np.concatenate([train_y,y.cpu().detach().numpy().reshape(-1)])\n",
    "\n",
    "train_output, train_y = np.e**train_output, np.e**train_y\n",
    "    \n",
    "for x , y in test_loader:\n",
    "    x, y = x.float().to(device), y.float().to(device)\n",
    "            \n",
    "    output = model(x, category_cols, category_dict, numeric_dict)\n",
    "    test_output = np.concatenate([test_output,output.cpu().detach().numpy().reshape(-1)])\n",
    "    test_y = np.concatenate([test_y,y.cpu().detach().numpy().reshape(-1)])\n",
    "\n",
    "test_output, test_y = np.e**test_output, np.e**test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\tRMSE: 373885 MAE(mean): 47672 MAE(median): 8509\n",
      "test\tRMSE: 403241 MAE(mean): 57119 MAE(median): 10399\n"
     ]
    }
   ],
   "source": [
    "print('train\\tRMSE: {:.0f} MAE(mean): {:.0f} MAE(median): {:.0f}'.format(\n",
    "    mean_squared_error(train_y, train_output, squared=False), \n",
    "    mean_absolute_error(train_y, train_output), \n",
    "    median_absolute_error(train_y, train_output)\n",
    "))\n",
    "print('test\\tRMSE: {:.0f} MAE(mean): {:.0f} MAE(median): {:.0f}'.format(\n",
    "    mean_squared_error(test_y, test_output, squared=False), \n",
    "    mean_absolute_error(test_y, test_output), \n",
    "    median_absolute_error(test_y, test_output)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = x_test[['chid']].copy()\n",
    "df_out['true'] = test_y\n",
    "df_out['pred'] = test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.to_csv('result/mlp_output.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
