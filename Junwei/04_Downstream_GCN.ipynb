{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from time import time\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error\n",
    "\n",
    "from Model import GCNEncoder, MLP_with_pretrain, Whole_model_GCN\n",
    "from utils import column_idx, make_edges_symmetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "shop_col = 'stonc_6_label'\n",
    "#shop_col = 'mcc'\n",
    "#shop_col = 'stonc_label'\n",
    "#shop_col = 'stonc_10_label'\n",
    "\n",
    "embedding_size = 64\n",
    "\n",
    "epochs = 400\n",
    "early_stop = 20\n",
    "batch_size = 2048\n",
    "learning_rate = 0.001\n",
    "\n",
    "pretrain_weights = './weights/GCNencoder_weights_stonc6'\n",
    "result_path = 'result/GCN_stonc6_weights.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_path = './data/sample'\n",
    "\n",
    "chid_dict_file_name = 'sample_50k_idx_map.npy'\n",
    "cdtx_file_name = 'sample_50k_cdtx.csv'\n",
    "cust_file_name = 'sample_50k_cust.csv'\n",
    "\n",
    "sample_chid_dict = os.path.join(sample_data_path, chid_dict_file_name)\n",
    "sample_cdtx_file = os.path.join(sample_data_path, cdtx_file_name)\n",
    "sample_cust_file = os.path.join(sample_data_path, cust_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "downstream_data_path = './data/downstream'\n",
    "\n",
    "x_train_file_name = 'x_train.csv'\n",
    "x_test_file_name = 'x_test.csv'\n",
    "y_train_file_name = 'y_train.csv'\n",
    "y_test_file_name = 'y_test.csv'\n",
    "\n",
    "x_train_file = os.path.join(downstream_data_path, x_train_file_name)\n",
    "x_test_file = os.path.join(downstream_data_path, x_test_file_name)\n",
    "y_train_file = os.path.join(downstream_data_path, y_train_file_name)\n",
    "y_test_file = os.path.join(downstream_data_path, y_test_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cdtx = pd.read_csv(sample_cdtx_file)\n",
    "df_cdtx.sort_values('csmdt')\n",
    "\n",
    "df_cust = pd.read_csv(sample_cust_file)\n",
    "df_cust.drop_duplicates(ignore_index=True, inplace=True)\n",
    "\n",
    "idx_map = np.load(sample_chid_dict, allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bnsfg                  2\n",
       "bnspt                338\n",
       "chid               50000\n",
       "csmdt                761\n",
       "iterm                 15\n",
       "mcc                  507\n",
       "objam              52132\n",
       "scity              11073\n",
       "tcode                  7\n",
       "hcefg                 10\n",
       "ecfg                   2\n",
       "etymd                 15\n",
       "stonc_tag             49\n",
       "stonc_label       202387\n",
       "stonm_label       212342\n",
       "stonc_6_label      78560\n",
       "stonc_10_label    128075\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cdtx.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(idx_map)\n",
    "for i , j in enumerate(sorted(df_cdtx[shop_col].unique())):\n",
    "    idx_map[j] = i+l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cdtx.chid = df_cdtx.chid.map(idx_map)\n",
    "df_cdtx[shop_col] = df_cdtx[shop_col].map(idx_map)\n",
    "\n",
    "df_cust.chid = df_cust.chid.map(idx_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cdtx.csmdt = df_cdtx.csmdt.apply(lambda x: x[:8]+'01')\n",
    "df_cdtx.objam = df_cdtx.objam.apply(lambda x: int(x))\n",
    "\n",
    "df_cust.data_dt = df_cust.data_dt.apply(lambda x: x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_cols = ['chid', 'data_dt']\n",
    "category_cols = ['masts', 'educd', 'naty', 'trdtp', 'poscd', 'cuorg']\n",
    "numeric_cols = sorted(set(df_cust.columns) - set(category_cols) - set(ignore_cols)) + ['objam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = {col: {value: index for index, value in enumerate(sorted(df_cust[col].unique()))} \n",
    "          for col in category_cols}\n",
    "\n",
    "df_cust[category_cols] = df_cust[category_cols].apply(lambda x: x.map(mapper[x.name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cdtx = df_cdtx[df_cdtx.csmdt < '2019-01-01']\n",
    "df_cust = df_cust[df_cust.data_dt == '2018-12-01'].sort_values(by=['chid'])\n",
    "\n",
    "df_cust['objam'] = np.ma.log(df_cdtx.groupby(['chid']).sum().objam.values/12).filled(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler = MinMaxScaler()\n",
    "df_cust[numeric_cols] = x_scaler.fit_transform(df_cust[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cust_ = df_cust[category_cols+numeric_cols]\n",
    "\n",
    "cust_feature = torch.Tensor(df_cust_.to_numpy())\n",
    "shop_feature = torch.zeros(len(idx_map)-cust_feature.shape[0], cust_feature.shape[1])\n",
    "x_feature = torch.cat([cust_feature, shop_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_pairs = df_cdtx[['chid', shop_col]].copy()\n",
    "edge_pairs.drop_duplicates(ignore_index=True, inplace=True)\n",
    "edge_pairs = edge_pairs.to_numpy().T\n",
    "\n",
    "edge_pairs = make_edges_symmetry(edge_pairs)\n",
    "edge_pairs = torch.LongTensor(edge_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(x_train_file)\n",
    "x_test = pd.read_csv(x_test_file)\n",
    "\n",
    "y_train = pd.read_csv(y_train_file)\n",
    "y_test = pd.read_csv(y_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_cols = ['chid']\n",
    "\n",
    "category_cols = ['masts', 'educd', 'naty', 'trdtp', 'poscd', 'cuorg']\n",
    "    \n",
    "numeric_cols = sorted(set(x_train.columns) - set(category_cols) - set(ignore_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dims = {col_name : len(uni)\n",
    "                 for col_name, uni in mapper.items()}\n",
    "category_dict = column_idx(df_cust_, category_cols)\n",
    "numeric_dict = column_idx(df_cust_, numeric_cols)\n",
    "\n",
    "\n",
    "input_dim = len(category_dict)*embedding_size + len(numeric_dict) + embedding_size\n",
    "\n",
    "layer_dims = [input_dim, 256, 128, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(torch.from_numpy(x_train.to_numpy()),\n",
    "                              torch.from_numpy(y_train.to_numpy()))\n",
    "train_loader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "test_dataset = TensorDataset(torch.from_numpy(x_test.to_numpy()),\n",
    "                              torch.from_numpy(y_test.to_numpy()))\n",
    "test_loader = DataLoader(dataset=test_dataset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train_model = GCNEncoder(input_dim-embedding_size, embedding_size, category_dims)\n",
    "pre_train_model.load_state_dict(torch.load(pretrain_weights))\n",
    "pre_train_model.train()\n",
    "\n",
    "down_stream_model = MLP_with_pretrain(category_dims, layer_dims, embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole_model_GCN(\n",
      "  (pre_train_model): GCNEncoder(\n",
      "    (conv1): GCNConv(408, 128)\n",
      "    (conv2): GCNConv(128, 64)\n",
      "    (embedding_dict): ModuleDict(\n",
      "      (masts): Embedding(3, 64)\n",
      "      (educd): Embedding(6, 64)\n",
      "      (naty): Embedding(2, 64)\n",
      "      (trdtp): Embedding(27, 64)\n",
      "      (poscd): Embedding(9, 64)\n",
      "      (cuorg): Embedding(30, 64)\n",
      "    )\n",
      "  )\n",
      "  (down_stream_model): MLP_with_pretrain(\n",
      "    (model): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=472, out_features=256, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=1, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (embedding_dict): ModuleDict(\n",
      "      (masts): Embedding(3, 64)\n",
      "      (educd): Embedding(6, 64)\n",
      "      (naty): Embedding(2, 64)\n",
      "      (trdtp): Embedding(27, 64)\n",
      "      (poscd): Embedding(9, 64)\n",
      "      (cuorg): Embedding(30, 64)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Whole_model_GCN(pre_train_model, down_stream_model).to(device)\n",
    "x_feature = x_feature.to(device)\n",
    "edge_index = edge_pairs.to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:15<00:00, 16.26it/s]\n",
      "  1%|          | 2/245 [00:00<00:17, 13.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "train loss:1017793,test loss:616035\n",
      "train MAE(mean):75510,test MAE(mean):80998\n",
      "train MAE(median):11454, test MAE(median):11200\n",
      "\tBetter!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:15<00:00, 15.79it/s]\n",
      "  0%|          | 1/245 [00:00<00:27,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1\n",
      "train loss:1021583,test loss:1358217\n",
      "train MAE(mean):71577,test MAE(mean):80649\n",
      "train MAE(median):10523, test MAE(median):10927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:15<00:00, 16.13it/s]\n",
      "  0%|          | 1/245 [00:00<00:24,  9.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2\n",
      "train loss:2406774,test loss:4631634\n",
      "train MAE(mean):75209,test MAE(mean):96482\n",
      "train MAE(median):10149, test MAE(median):10117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:14<00:00, 16.34it/s]\n",
      "  0%|          | 1/245 [00:00<00:25,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3\n",
      "train loss:3995127,test loss:4842196\n",
      "train MAE(mean):79138,test MAE(mean):99956\n",
      "train MAE(median):10065, test MAE(median):10643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:14<00:00, 16.81it/s]\n",
      "  1%|          | 2/245 [00:00<00:17, 13.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4\n",
      "train loss:24559718,test loss:24327715\n",
      "train MAE(mean):124776,test MAE(mean):179902\n",
      "train MAE(median):9976, test MAE(median):10344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:14<00:00, 16.88it/s]\n",
      "  1%|          | 2/245 [00:00<00:17, 13.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5\n",
      "train loss:23266563,test loss:8699180\n",
      "train MAE(mean):126290,test MAE(mean):117443\n",
      "train MAE(median):9991, test MAE(median):10771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:14<00:00, 16.73it/s]\n",
      "  0%|          | 1/245 [00:00<00:25,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6\n",
      "train loss:33717401,test loss:20814668\n",
      "train MAE(mean):148550,test MAE(mean):168194\n",
      "train MAE(median):9966, test MAE(median):10192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:14<00:00, 16.79it/s]\n",
      "  1%|          | 2/245 [00:00<00:17, 13.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7\n",
      "train loss:66859320,test loss:52134067\n",
      "train MAE(mean):235685,test MAE(mean):298812\n",
      "train MAE(median):9970, test MAE(median):10329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:14<00:00, 16.79it/s]\n",
      "  1%|          | 2/245 [00:00<00:17, 14.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8\n",
      "train loss:44307670,test loss:77739185\n",
      "train MAE(mean):169853,test MAE(mean):408301\n",
      "train MAE(median):9937, test MAE(median):10520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:14<00:00, 16.60it/s]\n",
      "  0%|          | 1/245 [00:00<00:25,  9.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9\n",
      "train loss:73019757,test loss:58584631\n",
      "train MAE(mean):237471,test MAE(mean):325395\n",
      "train MAE(median):9930, test MAE(median):10165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:14<00:00, 16.98it/s]\n",
      "  1%|          | 2/245 [00:00<00:16, 14.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10\n",
      "train loss:76516581,test loss:87303010\n",
      "train MAE(mean):248489,test MAE(mean):451510\n",
      "train MAE(median):9964, test MAE(median):10135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:14<00:00, 16.87it/s]\n",
      "  0%|          | 1/245 [00:00<00:24,  9.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11\n",
      "train loss:46807847,test loss:56822935\n",
      "train MAE(mean):188714,test MAE(mean):319272\n",
      "train MAE(median):9901, test MAE(median):10097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:14<00:00, 16.75it/s]\n",
      "  0%|          | 1/245 [00:00<00:25,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12\n",
      "train loss:46955675,test loss:43446163\n",
      "train MAE(mean):185497,test MAE(mean):263887\n",
      "train MAE(median):9892, test MAE(median):10090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:14<00:00, 16.62it/s]\n",
      "  1%|          | 2/245 [00:00<00:17, 13.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13\n",
      "train loss:68182707,test loss:35844111\n",
      "train MAE(mean):235931,test MAE(mean):230083\n",
      "train MAE(median):9939, test MAE(median):10355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:14<00:00, 17.06it/s]\n",
      "  1%|          | 2/245 [00:00<00:17, 13.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14\n",
      "train loss:67521476,test loss:27229317\n",
      "train MAE(mean):221207,test MAE(mean):192777\n",
      "train MAE(median):9961, test MAE(median):10171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:14<00:00, 16.87it/s]\n",
      "  1%|          | 2/245 [00:00<00:17, 14.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15\n",
      "train loss:41913663,test loss:56995900\n",
      "train MAE(mean):175346,test MAE(mean):317241\n",
      "train MAE(median):9882, test MAE(median):10395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:14<00:00, 16.77it/s]\n",
      "  1%|          | 2/245 [00:00<00:17, 14.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16\n",
      "train loss:75219734,test loss:40381708\n",
      "train MAE(mean):205715,test MAE(mean):248452\n",
      "train MAE(median):9895, test MAE(median):10172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:14<00:00, 16.78it/s]\n",
      "  1%|          | 2/245 [00:00<00:17, 14.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17\n",
      "train loss:34389088,test loss:33626999\n",
      "train MAE(mean):155264,test MAE(mean):218943\n",
      "train MAE(median):9919, test MAE(median):10198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:14<00:00, 16.84it/s]\n",
      "  0%|          | 0/245 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18\n",
      "train loss:42420085,test loss:59706202\n",
      "train MAE(mean):177036,test MAE(mean):324838\n",
      "train MAE(median):9877, test MAE(median):10169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:14<00:00, 16.80it/s]\n",
      "  1%|          | 2/245 [00:00<00:17, 14.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19\n",
      "train loss:39352486,test loss:33829693\n",
      "train MAE(mean):160491,test MAE(mean):218266\n",
      "train MAE(median):9882, test MAE(median):10066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:14<00:00, 16.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20\n",
      "train loss:28540343,test loss:42676495\n",
      "train MAE(mean):138068,test MAE(mean):254210\n",
      "train MAE(median):9934, test MAE(median):10215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_loss = 1e10\n",
    "early_cnt = 0\n",
    "RMSE = []\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    train_loss = 0\n",
    "    test_loss = 0\n",
    "    train_output = np.array([])\n",
    "    train_y = np.array([])\n",
    "    test_output = np.array([])\n",
    "    test_y = np.array([])\n",
    "    \n",
    "    for x , y in tqdm(train_loader):\n",
    "        x, y = x.float().to(device), y.float().to(device)\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(x, x_feature, edge_index, category_dict, numeric_dict)\n",
    "\n",
    "        loss = criterion(output, y)\n",
    "        train_loss += loss.item()\n",
    "        train_output = np.concatenate([train_output,output.cpu().detach().numpy().reshape(-1)])\n",
    "        train_y = np.concatenate([train_y,y.cpu().detach().numpy().reshape(-1)])\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    for x , y in test_loader:\n",
    "        x, y = x.float().to(device), y.float().to(device)\n",
    "        model.eval()        \n",
    "        output = model(x, x_feature, edge_index, category_dict, numeric_dict)\n",
    "        loss = criterion(output, y)\n",
    "        test_loss += loss.item()\n",
    "        test_output = np.concatenate([test_output,output.cpu().detach().numpy().reshape(-1)])\n",
    "        test_y = np.concatenate([test_y,y.cpu().detach().numpy().reshape(-1)])\n",
    "    \n",
    "    #train_loss = np.sqrt(train_loss/len(train_loader))\n",
    "    #test_loss = np.sqrt(test_loss/len(test_loader))\n",
    "    \n",
    "    train_output, train_y = np.e**train_output, np.e**train_y\n",
    "    train_RMSE = mean_squared_error(train_output, train_y, squared=False)\n",
    "    train_mean = mean_absolute_error(train_output, train_y)\n",
    "    train_median = median_absolute_error(train_output, train_y)\n",
    "    \n",
    "    test_output, test_y = np.e**test_output, np.e**test_y\n",
    "    test_RMSE = mean_squared_error(test_output, test_y, squared=False)\n",
    "    test_mean = mean_absolute_error(test_output, test_y)\n",
    "    test_median = median_absolute_error(test_output, test_y)\n",
    "    \n",
    "    print(f'epoch:{epoch}\\ntrain loss:{train_RMSE:.0f},test loss:{test_RMSE:.0f}\\ntrain MAE(mean):{train_mean:.0f},test MAE(mean):{test_mean:.0f}\\ntrain MAE(median):{train_median:.0f}, test MAE(median):{test_median:.0f}')\n",
    "    \n",
    "    if test_RMSE <= best_loss:\n",
    "        best_model_params = copy.deepcopy(model.state_dict())\n",
    "        best_loss = test_RMSE\n",
    "        print('\\tBetter!')\n",
    "        early_cnt = 0\n",
    "    else:\n",
    "        early_cnt += 1\n",
    "    \n",
    "    if early_cnt >= early_stop:\n",
    "        break\n",
    "\n",
    "model.load_state_dict(best_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:09<00:00, 26.48it/s]\n"
     ]
    }
   ],
   "source": [
    "train_output = np.array([])\n",
    "train_y = np.array([])\n",
    "test_output = np.array([])\n",
    "test_y = np.array([])\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for x , y in tqdm(train_loader):\n",
    "    x, y = x.float().to(device), y.float().to(device)\n",
    "\n",
    "    output = model(x, x_feature, edge_index, category_dict, numeric_dict)\n",
    "    train_output = np.concatenate([train_output,output.cpu().detach().numpy().reshape(-1)])\n",
    "    train_y = np.concatenate([train_y,y.cpu().detach().numpy().reshape(-1)])\n",
    "    \n",
    "for x , y in test_loader:\n",
    "    x, y = x.float().to(device), y.float().to(device)       \n",
    "    output = model(x, x_feature, edge_index, category_dict, numeric_dict)\n",
    "    test_output = np.concatenate([test_output,output.cpu().detach().numpy().reshape(-1)])\n",
    "    test_y = np.concatenate([test_y,y.cpu().detach().numpy().reshape(-1)])\n",
    "    \n",
    "train_output, train_y = np.e**train_output, np.e**train_y\n",
    "test_output, test_y = np.e**test_output, np.e**test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\tRMSE: 1015456.50 MSE(mean): 73420.35 MSE(median): 10492.29\n",
      "test\tRMSE: 615057.77 MSE(mean): 80873.78 MSE(median): 10972.66\n"
     ]
    }
   ],
   "source": [
    "print('train\\tRMSE: {:.2f} MSE(mean): {:.2f} MSE(median): {:.2f}'.format(\n",
    "    mean_squared_error(train_y, train_output, squared=False), \n",
    "    mean_absolute_error(train_y, train_output), \n",
    "    median_absolute_error(train_y, train_output)\n",
    "))\n",
    "print('test\\tRMSE: {:.2f} MSE(mean): {:.2f} MSE(median): {:.2f}'.format(\n",
    "    mean_squared_error(test_y, test_output, squared=False), \n",
    "    mean_absolute_error(test_y, test_output), \n",
    "    median_absolute_error(test_y, test_output)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = x_test[['chid']].copy()\n",
    "df_out['true'] = test_y\n",
    "df_out['pred'] = test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chid</th>\n",
       "      <th>true</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11755.999087</td>\n",
       "      <td>7.328887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>35519.989944</td>\n",
       "      <td>51.180935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>150494.007197</td>\n",
       "      <td>19748.708809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3671.000531</td>\n",
       "      <td>214489.741070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>62179.981812</td>\n",
       "      <td>6916.797713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>49997</td>\n",
       "      <td>235115.953642</td>\n",
       "      <td>15049.737520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>49998</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1233.773528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>49998</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>433.081405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>49999</td>\n",
       "      <td>2747.000494</td>\n",
       "      <td>3615.231416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>49999</td>\n",
       "      <td>116310.945179</td>\n",
       "      <td>2194.076990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        chid           true           pred\n",
       "0          0   11755.999087       7.328887\n",
       "1          0   35519.989944      51.180935\n",
       "2          1  150494.007197   19748.708809\n",
       "3          1    3671.000531  214489.741070\n",
       "4          2   62179.981812    6916.797713\n",
       "...      ...            ...            ...\n",
       "99995  49997  235115.953642   15049.737520\n",
       "99996  49998       1.000000    1233.773528\n",
       "99997  49998       1.000000     433.081405\n",
       "99998  49999    2747.000494    3615.231416\n",
       "99999  49999  116310.945179    2194.076990\n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.to_csv(result_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
