{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, GAE, VGAE\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_path = './data/'\n",
    "chid_dict_file = 'sample_idx_map.npy'\n",
    "cdtx_file = 'sample_zip_if_cca_cdtx0001_hist.csv'\n",
    "cust_f_file = 'sample_zip_if_cca_cust_f.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 (6654938, 10) (1176172, 32)\n"
     ]
    }
   ],
   "source": [
    "idx_map = np.load(os.path.join(sample_path, chid_dict_file), allow_pickle=True).tolist()\n",
    "df_cdtx = pd.read_csv(os.path.join(sample_path, cdtx_file)) # 交易記錄檔\n",
    "df_cust_f = pd.read_csv(os.path.join(sample_path, cust_f_file)) # user feature\n",
    "df_cust_f.drop_duplicates(ignore_index=True, inplace=True)\n",
    "\n",
    "print(len(idx_map), df_cdtx.shape, df_cust_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "502it [00:00, 419932.31it/s]\n"
     ]
    }
   ],
   "source": [
    "l = len(idx_map)\n",
    "for i, j  in tqdm(enumerate(set(df_cdtx.mcc))):\n",
    "    idx_map[j] = i+l\n",
    "\n",
    "df_cdtx.chid = df_cdtx.chid.map(idx_map)\n",
    "df_cdtx.mcc = df_cdtx.mcc.map(idx_map)\n",
    "\n",
    "df_cust_f.chid = df_cust_f.chid.map(idx_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cust_f_pre = df_cust_f[df_cust_f.data_ym == '2019-01-01'].sort_values(by=['chid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_cols = ['masts', 'educd', 'naty', 'trdtp', 'poscd', 'cuorg']\n",
    "\n",
    "numeric_cols = sorted(set(df_cust_f.columns) - set(category_cols) - set(['chid', 'data_ym', 'data_dt']), \n",
    "                      key=list(df_cust_f.columns).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chid</th>\n",
       "      <th>data_ym</th>\n",
       "      <th>monin</th>\n",
       "      <th>wrky</th>\n",
       "      <th>first_mob</th>\n",
       "      <th>data_dt</th>\n",
       "      <th>masts</th>\n",
       "      <th>educd</th>\n",
       "      <th>naty</th>\n",
       "      <th>trdtp</th>\n",
       "      <th>...</th>\n",
       "      <th>constant_u2_ind</th>\n",
       "      <th>constant_u3_ind</th>\n",
       "      <th>constant_u4_ind</th>\n",
       "      <th>constant_l2_ind</th>\n",
       "      <th>constant_l3_ind</th>\n",
       "      <th>constant_l4_ind</th>\n",
       "      <th>constant_change</th>\n",
       "      <th>growth_rate</th>\n",
       "      <th>monotone_up</th>\n",
       "      <th>monotone_down</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>827843</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>173472</td>\n",
       "      <td>0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107093</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>248914</td>\n",
       "      <td>0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        chid     data_ym   monin  wrky  first_mob     data_dt  masts  educd  \\\n",
       "827843     0  2019-01-01  173472     0      192.0  2019-02-01      2      4   \n",
       "107093     1  2019-01-01  248914     0      192.0  2019-02-01      0      1   \n",
       "\n",
       "        naty  trdtp  ...  constant_u2_ind  constant_u3_ind  constant_u4_ind  \\\n",
       "827843     1     20  ...              0.0              0.0              0.0   \n",
       "107093     1     22  ...              0.0              0.0              0.0   \n",
       "\n",
       "        constant_l2_ind  constant_l3_ind  constant_l4_ind  constant_change  \\\n",
       "827843              1.0              0.0              0.0              0.0   \n",
       "107093              0.0              0.0              0.0              0.0   \n",
       "\n",
       "        growth_rate  monotone_up  monotone_down  \n",
       "827843          0.8          0.0            3.0  \n",
       "107093          0.0          0.0            0.0  \n",
       "\n",
       "[2 rows x 32 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper = {col: {value: index for index, value in enumerate(sorted(df_cust_f_pre[col].unique()))} \n",
    "          for col in category_cols}\n",
    "\n",
    "df_cust_f_pre.loc[:,category_cols] = df_cust_f_pre[category_cols].apply(lambda x: x.map(mapper[x.name]))\n",
    "\n",
    "print(df_cust_f_pre.shape)\n",
    "df_cust_f_pre.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cust_f_pre.drop(columns=['data_ym', 'data_dt'], inplace=True)\n",
    "df_cust_f_pre = df_cust_f_pre[category_cols+numeric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler = MinMaxScaler()\n",
    "df_cust_f_pre[numeric_cols] = x_scaler.fit_transform(df_cust_f_pre[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_feature = torch.Tensor(df_cust_f_pre.to_numpy())\n",
    "x_feature = torch.cat([x_feature, torch.zeros(len(idx_map)-x_feature.shape[0],x_feature.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(518928, 2) (518928, 2)\n"
     ]
    }
   ],
   "source": [
    "df_cdtx = df_cdtx[df_cdtx.csmdt < '2019-01-01']\n",
    "edge_index = df_cdtx.iloc[:,[2,5]].drop_duplicates().to_numpy()\n",
    "\n",
    "def make_edges_symmetry(edge_index):\n",
    "    new_edge = []\n",
    "    for i in edge_index:\n",
    "        new_edge.append(np.array([i[1],i[0]]))\n",
    "    new_edge = np.concatenate([new_edge],0)\n",
    "    print(new_edge.shape, edge_index.shape)\n",
    "    return torch.LongTensor(np.concatenate([edge_index,new_edge], 0).T)\n",
    "\n",
    "edge_index = make_edges_symmetry(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(518928, 2)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cdtx.iloc[:,[2,5]].drop_duplicates().to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(x=x_feature, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(518928, 2) (518928, 2)\n"
     ]
    }
   ],
   "source": [
    "def sample_neg_edges(pos_edges, num_nodes, n_user):\n",
    "    row , col = pos_edges\n",
    "    mask = row < col\n",
    "    row, col = row[mask], col[mask]\n",
    "    neg_adj_mask = torch.ones(num_nodes, num_nodes, dtype=torch.uint8)\n",
    "    neg_adj_mask = neg_adj_mask.triu(diagonal=1).to(torch.bool)\n",
    "    neg_adj_mask[row, col] = 0\n",
    "    neg_row, neg_col = neg_adj_mask[:n_user, n_user:].nonzero(as_tuple=False).t()\n",
    "    neg_col = neg_col+n_user\n",
    "    perm = torch.randperm(row.size(0))\n",
    "    neg_row, neg_col = neg_row[perm], neg_col[perm]\n",
    "    neg_edge_index = torch.cat([neg_row.view(1,-1), neg_col.view(1,-1)],0)\n",
    "    return make_edges_symmetry(neg_edge_index.T)\n",
    "\n",
    "neg_edge_index = sample_neg_edges(data.edge_index, 50502, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1037856])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_index(x, feature_cols):\n",
    "    feature_idx = {}\n",
    "    x_cols = list(x.columns)\n",
    "    for i in feature_cols:\n",
    "        feature_idx[i] = x_cols.index(i)\n",
    "        \n",
    "    return feature_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dict = feature_index(df_cust_f_pre, category_cols)\n",
    "numeric_dict = feature_index(df_cust_f_pre, numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'masts': 0, 'educd': 1, 'naty': 2, 'trdtp': 3, 'poscd': 4, 'cuorg': 5}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels , category_cols, category_dims):\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True)\n",
    "        self.conv2 = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "        self.embedding_dict = torch.nn.ModuleDict({category_col:torch.nn.Embedding(category_dim,\n",
    "                                                                                   64)\n",
    "                                                   for category_col, category_dim in zip(category_cols,category_dims)})\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        category_embeddings = [self.embedding_dict[item[0]](x[:,item[1]].long()) for item in category_dict.items()]\n",
    "        category_embeddings = torch.cat(category_embeddings, -1)\n",
    "        numeric_idx = torch.LongTensor(list(numeric_dict.values()))\n",
    "        x = torch.cat([category_embeddings, x[:,numeric_idx]], -1)\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "class LinearEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, category_cols, category_dims):\n",
    "        super(LinearEncoder, self).__init__()\n",
    "        self.conv = GCNConv(in_channels, out_channels, cached=True)\n",
    "        self.embedding_dict = torch.nn.ModuleDict({category_col:torch.nn.Embedding(category_dim,\n",
    "                                                                                   out_channels)\n",
    "                                                   for category_col, category_dim in zip(category_cols,category_dims)})\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        category_embeddings = [self.embedding_dict[item[0]](x[:,item[1]].long()) for item in category_dict.items()]\n",
    "        category_embeddings = torch.cat(category_embeddings, -1)\n",
    "        numeric_idx = torch.LongTensor(list(numeric_dict.values()))\n",
    "        x = torch.cat([category_embeddings, x[:,numeric_idx]], -1)\n",
    "        \n",
    "        return self.conv(x, edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dims = [df_cust_f[feat].nunique() for feat in category_cols]\n",
    "out_channels = 64\n",
    "num_features = len(category_dict)*64 + len(numeric_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GAE(GCNEncoder(num_features, out_channels, category_cols, category_dims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "x = data.x.to(device)\n",
    "train_pos_edge_index = data.edge_index.to(device)\n",
    "train_neg_edge_index = neg_edge_index.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(x, train_pos_edge_index)\n",
    "    loss = model.recon_loss(z, train_pos_edge_index, )\n",
    "    if False:\n",
    "        loss = loss + (1 / data.num_nodes) * model.kl_loss()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, train_pos_edge_index)\n",
    "        \n",
    "    return model.test(z, pos_edge_index, neg_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 23.783863067626953\n",
      "2 28.18710708618164\n",
      "3 26.689922332763672\n",
      "4 17.434524536132812\n",
      "5 5.4241108894348145\n",
      "6 2.142585039138794\n",
      "7 2.0948808193206787\n",
      "8 1.979941964149475\n",
      "9 1.5609272718429565\n",
      "10 1.2508572340011597\n",
      "11 1.090618371963501\n",
      "12 0.9846475720405579\n",
      "13 0.9202628135681152\n",
      "14 0.8682698011398315\n",
      "15 0.8347603678703308\n",
      "16 0.8161513805389404\n",
      "17 0.8120492100715637\n",
      "18 0.805556058883667\n",
      "19 0.8025895357131958\n",
      "20 0.795393705368042\n",
      "21 0.7936538457870483\n",
      "22 0.7914948463439941\n",
      "23 0.7949106693267822\n",
      "24 0.7892694473266602\n",
      "25 0.7866370677947998\n",
      "26 0.789164662361145\n",
      "27 0.7839850187301636\n",
      "28 0.7835958003997803\n",
      "29 0.7812873125076294\n",
      "30 0.782378613948822\n",
      "31 0.7804045081138611\n",
      "32 0.7778943181037903\n",
      "33 0.7776350378990173\n",
      "34 0.7747756838798523\n",
      "35 0.775317907333374\n",
      "36 0.7744396924972534\n",
      "37 0.7744811773300171\n",
      "38 0.7700278759002686\n",
      "39 0.772037923336029\n",
      "40 0.7688952684402466\n",
      "41 0.7697527408599854\n",
      "42 0.7682616114616394\n",
      "43 0.7680343389511108\n",
      "44 0.7672072052955627\n",
      "45 0.7653307318687439\n",
      "46 0.765592098236084\n",
      "47 0.7648864984512329\n",
      "48 0.7644879221916199\n",
      "49 0.7642239332199097\n",
      "50 0.7623234391212463\n",
      "51 0.7625147700309753\n",
      "52 0.7626256942749023\n",
      "53 0.762942910194397\n",
      "54 0.7618074417114258\n",
      "55 0.761233389377594\n",
      "56 0.7603417038917542\n",
      "57 0.7600072622299194\n",
      "58 0.7590986490249634\n",
      "59 0.7592346668243408\n",
      "60 0.7595028281211853\n",
      "61 0.7590516209602356\n",
      "62 0.758216142654419\n",
      "63 0.7580539584159851\n",
      "64 0.7569068670272827\n",
      "65 0.7569829225540161\n",
      "66 0.7569378614425659\n",
      "67 0.7560524344444275\n",
      "68 0.7560287117958069\n",
      "69 0.755602240562439\n",
      "70 0.7553637027740479\n",
      "71 0.7555221319198608\n",
      "72 0.7538754343986511\n",
      "73 0.754909873008728\n",
      "74 0.7536206245422363\n",
      "75 0.7527861595153809\n",
      "76 0.753738284111023\n",
      "77 0.7529358863830566\n",
      "151 0.7460529804229736\n",
      "152 0.7471156716346741\n",
      "153 0.7462196946144104\n",
      "154 0.7469319105148315\n",
      "155 0.7458791732788086\n",
      "156 0.7457834482192993\n",
      "157 0.7459465265274048\n",
      "158 0.7458425760269165\n",
      "159 0.745535135269165\n",
      "160 0.7445468902587891\n",
      "161 0.7456289529800415\n",
      "162 0.7453911900520325\n",
      "163 0.7452728748321533\n",
      "164 0.7446826696395874\n",
      "165 0.7447576522827148\n",
      "166 0.7454450726509094\n",
      "167 0.7452170848846436\n",
      "168 0.745521605014801\n",
      "169 0.7456368803977966\n",
      "170 0.7445891499519348\n",
      "171 0.7444701194763184\n",
      "172 0.7453693151473999\n",
      "173 0.7449156641960144\n",
      "174 0.7448758482933044\n",
      "175 0.7443802356719971\n",
      "176 0.7443927526473999\n",
      "177 0.7445475459098816\n",
      "178 0.7441531419754028\n",
      "179 0.7432703375816345\n",
      "180 0.7435190081596375\n",
      "181 0.7429527044296265\n",
      "182 0.7434037327766418\n",
      "183 0.7426416873931885\n",
      "184 0.74378502368927\n",
      "185 0.7431958913803101\n",
      "186 0.7438759207725525\n",
      "187 0.7432187795639038\n",
      "188 0.7427042126655579\n",
      "189 0.7428149580955505\n",
      "190 0.7424811124801636\n",
      "191 0.7431657910346985\n",
      "192 0.7429627180099487\n",
      "193 0.7426773309707642\n",
      "194 0.7421873211860657\n",
      "195 0.7420345544815063\n",
      "196 0.7416968941688538\n",
      "197 0.7417634725570679\n",
      "198 0.7429179549217224\n",
      "199 0.7406861186027527\n",
      "200 0.7420576214790344\n",
      "201 0.7404091358184814\n",
      "202 0.7415098547935486\n",
      "203 0.7414113879203796\n",
      "204 0.7408391833305359\n",
      "205 0.741294801235199\n",
      "206 0.7406808137893677\n",
      "207 0.7411291003227234\n",
      "208 0.7402292490005493\n",
      "209 0.7405106425285339\n",
      "210 0.7404657602310181\n",
      "211 0.7406774759292603\n",
      "212 0.7406420707702637\n",
      "213 0.740483820438385\n",
      "214 0.7414590120315552\n",
      "215 0.7403320074081421\n",
      "216 0.740257203578949\n",
      "217 0.7404395937919617\n",
      "218 0.7400110960006714\n",
      "219 0.7402233481407166\n",
      "220 0.7400193810462952\n",
      "221 0.7390828728675842\n",
      "222 0.7392734289169312\n",
      "223 0.7400471568107605\n",
      "224 0.7398183941841125\n",
      "225 0.7397934794425964\n",
      "226 0.7387966513633728\n",
      "227 0.7387804985046387\n",
      "228 0.7385667562484741\n",
      "229 0.7384923696517944\n",
      "230 0.7381466031074524\n",
      "231 0.7390621900558472\n",
      "232 0.7381982207298279\n",
      "233 0.7383657693862915\n",
      "234 0.7370253205299377\n",
      "235 0.7379351854324341\n",
      "236 0.7372539639472961\n",
      "237 0.7369906306266785\n",
      "238 0.7368857860565186\n",
      "239 0.7370113134384155\n",
      "240 0.7370263934135437\n",
      "241 0.7377458214759827\n",
      "242 0.7364927530288696\n",
      "243 0.7373308539390564\n",
      "244 0.736712634563446\n",
      "245 0.7360644340515137\n",
      "246 0.735244870185852\n",
      "247 0.73663330078125\n",
      "248 0.7361817955970764\n",
      "249 0.736514687538147\n",
      "250 0.7368236780166626\n",
      "251 0.7357300519943237\n",
      "252 0.7354120016098022\n",
      "253 0.735424280166626\n",
      "254 0.7352961897850037\n",
      "255 0.7358764410018921\n",
      "256 0.7347434759140015\n",
      "257 0.7351936101913452\n",
      "258 0.735445499420166\n",
      "259 0.7347334027290344\n",
      "260 0.7354278564453125\n",
      "261 0.7341667413711548\n",
      "262 0.7344774007797241\n",
      "263 0.7347686290740967\n",
      "264 0.7354640364646912\n",
      "265 0.7344375848770142\n",
      "266 0.73464435338974\n",
      "267 0.7343477010726929\n",
      "268 0.7362197637557983\n",
      "269 0.7341315150260925\n",
      "270 0.7341694235801697\n",
      "271 0.7333904504776001\n",
      "272 0.7332716584205627\n",
      "273 0.7340381145477295\n",
      "274 0.7338148951530457\n",
      "275 0.7329539060592651\n",
      "276 0.7334624528884888\n",
      "277 0.7333338260650635\n",
      "278 0.7325423955917358\n",
      "279 0.7332361340522766\n",
      "280 0.7330819368362427\n",
      "281 0.732904851436615\n",
      "282 0.7331218719482422\n",
      "283 0.7333552241325378\n",
      "284 0.7324910759925842\n",
      "285 0.7324467301368713\n",
      "286 0.7330223321914673\n",
      "287 0.7327723503112793\n",
      "288 0.7323497533798218\n",
      "289 0.73375403881073\n",
      "290 0.7337843179702759\n",
      "291 0.7330912351608276\n",
      "292 0.7342431545257568\n",
      "293 0.7342103123664856\n",
      "294 0.7327979207038879\n",
      "295 0.7330816984176636\n",
      "296 0.7335243821144104\n",
      "297 0.7339470386505127\n",
      "298 0.7339674830436707\n",
      "299 0.7332808971405029\n",
      "300 0.7327451705932617\n",
      "301 0.7334508895874023\n",
      "302 0.7354710102081299\n",
      "303 0.7327954769134521\n",
      "304 0.7361162900924683\n",
      "305 0.7423903942108154\n",
      "306 0.7374231219291687\n",
      "307 0.7505791187286377\n",
      "308 0.751543402671814\n",
      "309 0.7730833888053894\n",
      "310 0.748394787311554\n",
      "311 0.7532288432121277\n",
      "312 0.736491322517395\n",
      "313 0.7407894134521484\n",
      "314 0.741664707660675\n",
      "315 0.7417444586753845\n",
      "316 0.7405379414558411\n",
      "317 0.7694274187088013\n",
      "318 0.7556771636009216\n",
      "319 0.7388741374015808\n",
      "320 0.7512418031692505\n",
      "321 0.7483144998550415\n",
      "322 0.7393639087677002\n",
      "323 0.7416467070579529\n",
      "324 0.7440882325172424\n",
      "325 0.7383323311805725\n",
      "326 0.7418696284294128\n",
      "327 0.7435206174850464\n",
      "328 0.7405699491500854\n",
      "329 0.7372709512710571\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-1e8d550a4970>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-27cd7818ebcd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pos_edge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecon_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pos_edge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkl_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch_geometric/nn/models/autoencoder.py\u001b[0m in \u001b[0;36mrecon_loss\u001b[0;34m(self, z, pos_edge_index, neg_edge_index)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mpos_edge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_self_loops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_edge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mneg_edge_index\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0mneg_edge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnegative_sampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_edge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         neg_loss = -torch.log(1 -\n\u001b[1;32m    100\u001b[0m                               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_edge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch_geometric/utils/negative_sampling.py\u001b[0m in \u001b[0;36mnegative_sampling\u001b[0;34m(edge_index, num_nodes, num_neg_samples, method, force_undirected)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mperm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_neg_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mperm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_neg_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36misin\u001b[0;34m(element, test_elements, assume_unique, invert)\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     return in1d(element, test_elements, assume_unique=assume_unique,\n\u001b[0;32m--> 697\u001b[0;31m                 invert=invert).reshape(element.shape)\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36min1d\u001b[0;34m(ar1, ar2, assume_unique, invert)\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;31m# here. The values from the first array should always come before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;31m# the values from the second array.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mergesort'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m     \u001b[0msar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minvert\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 400 + 1):\n",
    "    loss = train()\n",
    "    print(epoch, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = model.encode(x, train_pos_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = z.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('GCNEncoder_0126', z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
