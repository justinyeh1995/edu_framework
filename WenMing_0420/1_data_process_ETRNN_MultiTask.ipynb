{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question: \n",
    "- chid_dict_file 和 chid_array 沒有對應起來 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from tqdm import tqdm, trange\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_path = '../data'\n",
    "specific_path = './data/sample_50k'\n",
    "\n",
    "chid_file = os.path.join(sample_path, 'sample_chid.txt') # originally: 'sample_50k_chid.txt'\n",
    "cdtx_file = os.path.join(sample_path, 'sample_zip_if_cca_cdtx0001_hist.csv') # \n",
    "cust_f_file = os.path.join(sample_path, 'sample_zip_if_cca_cust_f.csv') # originally: 'sample_50k_cust_f.json'\n",
    "chid_dict_file = os.path.join(sample_path, 'sample_idx_map.npy') # 此檔案是在 ./data/sample_50k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load 使用者 id 轉換檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000,), 50000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chid_array = np.loadtxt(chid_file, dtype=np.str)\n",
    "chid_dict = np.load(chid_dict_file, allow_pickle=True).item()\n",
    "\n",
    "for i in range(len(chid_array)):\n",
    "    assert chid_dict[chid_array[i]] == i\n",
    "\n",
    "chid_array.shape, len(chid_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load 特徵檔, json -> dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# load 特徵檔, json -> dataframe\n",
    "t0 = time()\n",
    "with open(cust_f_file) as f:\n",
    "    cust_f_dict = json.load(f)\n",
    "    \n",
    "cust_f_rows = np.array(list(map(lambda x:list(x.values()), cust_f_dict.values())))\n",
    "cust_f_cols = list(cust_f_dict.get('0').keys())    \n",
    "df_cust_f = pd.DataFrame(data=cust_f_rows, columns=cust_f_cols)\n",
    "\n",
    "df_cust_f.data_dt = df_cust_f.data_dt.apply(lambda x: x[:-len('T00:00:00.000Z')])\n",
    "df_cust_f.sort_values(by=['data_dt', 'chid'], inplace=True, ignore_index=True)\n",
    "df_cust_f.drop_duplicates(ignore_index=True, inplace=True)\n",
    "\n",
    "print(time() - t0)\n",
    "\n",
    "df_cust_f.shape, df_cust_f.chid.nunique()\n",
    "'''\n",
    "\n",
    "t0 = time()\n",
    "df_cust_f = pd.read_csv(cust_f_file, skipinitialspace=True)\n",
    "df_cust_f.sort_values(by=['data_dt', 'chid'], inplace=True, ignore_index=True)\n",
    "df_cust_f.drop_duplicates(ignore_index=True, inplace=True)\n",
    "print(time() - t0)\n",
    "\n",
    "print(df_cust_f.shape, df_cust_f.chid.nunique())\n",
    "assert len(set(df_cust_f.chid)-set(chid_array)) == 0 and len(set(chid_array)-set(df_cust_f.chid)) == 0\n",
    "df_cust_f.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load 消費檔 (原始 json 已經轉為 dataframe) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "with open(cdtx_file) as f:\n",
    "    cdtx_dict = json.load(f)\n",
    "    \n",
    "cdtx_rows = np.array(list(map(lambda x:list(x.values()), cdtx_dict.values())))\n",
    "cdtx_cols = list(cdtx_dict.get('0').keys())    \n",
    "df_cdtx = pd.DataFrame(data=cdtx_rows, columns=cdtx_cols)\n",
    "\n",
    "df_cdtx.csmdt = df_cdtx.csmdt.apply(lambda x: x[:-len('T00:00:00.000Z')])\n",
    "df_cdtx.sort_values(by=['csmdt', 'chid'], inplace=True, ignore_index=True)\n",
    "df_cdtx.objam = df_cdtx.objam.astype(np.int64)\n",
    "\n",
    "'''\n",
    "\n",
    "t0 = time()\n",
    "df_cdtx = pd.read_csv(cdtx_file, skipinitialspace=True)\n",
    "# df_cdtx.csmdt.apply(lambda x: x[:-len('T00:00:00.000Z')]) 天以後的資訊已經移除。\n",
    "df_cdtx.sort_values(by=['csmdt', 'chid'], inplace=True, ignore_index=True)\n",
    "# df_cdtx.objam = df_cdtx.objam.astype(np.int64) # 交易金額已經是int64 \n",
    "print(time() - t0)\n",
    "\n",
    "df_cdtx.shape, df_cdtx.chid.nunique()\n",
    "\n",
    "print(df_cdtx.shape, df_cdtx.chid.nunique())\n",
    "\n",
    "# assert len(set(df_cdtx.chid)-set(chid_array)) == 0 and len(set(chid_array)-set(df_cdtx.chid)) == 0\n",
    "assert type(df_cdtx.objam[0]) == np.int64\n",
    "assert len(df_cdtx.csmdt[0]) == 10\n",
    "\n",
    "df_cdtx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cdtx = df_cdtx.iloc[:5000]\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''np.mean(df_cdtx.objam)\n",
    "\n",
    "import matplotlib.pylab as plt \n",
    "plt.hist(np.log10(1+df_cdtx.objam),bins=100)\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add month column, chid convert to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'month' not in df_cdtx.columns\n",
    "df_cdtx.chid = df_cdtx.chid.map(chid_dict)+1\n",
    "print(df_cdtx.chid.nunique())\n",
    "# assert max(df_cdtx.chid) == len(chid_array)\n",
    "df_cdtx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 取得整個月的 objam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "cdtx_group = df_cdtx[['chid', 'month', 'objam']].groupby(['chid', 'month'])\n",
    "\n",
    "cdtx_sum = cdtx_group.sum() # 總金額\n",
    "cdtx_mean = cdtx_group.mean() # 平均金額\n",
    "cdtx_count = cdtx_group.count() # 消費次數\n",
    "del cdtx_group \n",
    "gc.collect()\n",
    "\n",
    "# cdtx_group = df_cdtx[['chid', 'month', 'stonc_6_label']].drop_duplicates().groupby(['chid', 'month'])\n",
    "# cdtx_shop_kind_count = cdtx_group.count()\n",
    "\n",
    "# del cdtx_group \n",
    "# gc.collect()\n",
    "\n",
    "# del df_cdtx \n",
    "# gc.collect()\n",
    "\n",
    "df_cdtx_objam = pd.DataFrame(list(map(list, cdtx_sum.index)), columns=['chid', 'data_dt'])\n",
    "df_cdtx_objam['objam_sum'] = cdtx_sum.values[:, 0]\n",
    "df_cdtx_objam['objam_mean'] = cdtx_mean.values[:, 0]\n",
    "df_cdtx_objam['trans_count'] = cdtx_count.values[:, 0] # 交易次數\n",
    "\n",
    "# df_cdtx_objam['shop_count'] = cdtx_shop_kind_count.values[:, 0] # 一個月內消費店家種類個數\n",
    "\n",
    "del cdtx_sum, cdtx_mean, cdtx_count# , cdtx_shop_kind_count\n",
    "gc.collect()\n",
    "\n",
    "df_cdtx_objam.shape\n",
    "# 每個顧客，每個月會有一個數值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outer_product_table_of_chids_and_months(df_cdtx):\n",
    "    '''\n",
    "    產生一個包含所有顧客與所有月份的一個table。column的數量為: (# chids) X (# months)\n",
    "    '''\n",
    "    list_chid = sorted(df_cdtx.chid.unique())\n",
    "    list_month = sorted(df_cdtx.month.unique())[:]\n",
    "    \n",
    "    df_full_y_sum = pd.DataFrame({\n",
    "        'chid': list_chid*len(list_month),\n",
    "    }).sort_values(by='chid', ignore_index=True) # 讓list_chid重複的次數和月的數量一樣多\n",
    "    df_full_y_sum['data_dt'] = list_month*len(list_chid) # 讓list_month重複出現的次數和顧客數一樣多\n",
    "\n",
    "    return df_full_y_sum \n",
    "\n",
    "df_full_y_sum = outer_product_table_of_chids_and_months(df_cdtx)\n",
    "df_full_y_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## join objam - 併入每個顧客每個月的目標指數 \n",
    "df_full_y_sum = df_full_y_sum.merge(df_cdtx_objam, \n",
    "                                    how='left', \n",
    "                                    left_on=['chid', 'data_dt'], \n",
    "                                    right_on=['chid', 'data_dt']).fillna(0)\n",
    "\n",
    "df_full_y_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## join feature - 併入每個顧客每個月的特徵 \n",
    "# p.s., df_cust_f 內存的剛好是每個月初的狀態\n",
    "df_full_y_sum = df_full_y_sum.merge(df_cust_f, \n",
    "                                    how='inner', \n",
    "                                    left_on=['chid', 'data_dt'], \n",
    "                                    right_on=['chid', 'data_dt']).fillna(0)\n",
    "df_full_y_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本月 前1、2月 平均金額 \n",
    "df_full_y_sum.insert(6, 'objam_mean_M3', 0)\n",
    "for chid in tqdm(sorted(df_full_y_sum.chid.unique())):\n",
    "    mask = df_full_y_sum.chid == chid\n",
    "    \n",
    "    temp = (df_full_y_sum.loc[mask, 'objam_sum'] + \n",
    "            df_full_y_sum.loc[mask, 'objam_sum'].shift(1).fillna(0) + \n",
    "            df_full_y_sum.loc[mask, 'objam_sum'].shift(2).fillna(0)) // 3   \n",
    "    \n",
    "    df_full_y_sum.loc[mask, 'objam_mean_M3'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將時間欄位轉為datatime64形式\n",
    "df_full_y_sum.data_dt = df_full_y_sum.data_dt.astype(np.datetime64)\n",
    "df_cdtx.csmdt = df_cdtx.csmdt.astype(np.datetime64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cdtx.sort_values(by=['chid', 'csmdt'], ignore_index=True, inplace=True)\n",
    "# 距離上次消費的天數\n",
    "df_cdtx['timestamp_0'] = (df_cdtx.csmdt - df_cdtx.csmdt.shift()).apply(lambda x: x.days).fillna(0) \n",
    "# 距離2018-01-01的天數\n",
    "df_cdtx['timestamp_1'] = (df_cdtx.csmdt - np.datetime64('2018-01-01')).apply(lambda x: x.days).fillna(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_cdtx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d3aae5f516a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mchid_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cdtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchid\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mchid_pre\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mchid_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_cdtx' is not defined"
     ]
    }
   ],
   "source": [
    "import tqdm \n",
    "# drop error row \n",
    "# 這個cell執行的前提是df_cdtx是先依造chid排，然後再依造csmdt排\n",
    "# 之所以要這樣做是因為前一次消費的時間差應該要在同一個消費者之間去做計算，但是前面的code沒辦法避免到這一點。\n",
    "# i.e., df_cdtx['timestamp_0'] = (df_cdtx.csmdt - df_cdtx.csmdt.shift()).apply(lambda x: x.days).fillna(0)  \n",
    "# 因此我們就在換chid的時候，把timestamp_0設為 0。\n",
    "# TODO: 此cell應該要和timestamp_0的建立統一起執行。\n",
    "\n",
    "mask_list = []\n",
    "chid_pre = -1 \n",
    "\n",
    "for i, chid in tqdm(enumerate(df_cdtx.chid.values)):\n",
    "    if chid != chid_pre: # 不是-1，也不是前一個chid，代表是沒有算到另一個chid的前一次時間。\n",
    "        chid_pre = chid\n",
    "        mask_list.append(i)\n",
    "        \n",
    "df_cdtx.loc[mask_list, 'timestamp_0'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time series columns\n",
    "# - 把類別型和數值型的時序input抓出來。\n",
    "# TODO: Question) 有哪些df_cdtx的資料為非input的資料，而是output的資料。\n",
    "\n",
    "category_cols = ['chid', 'bnsfg', 'iterm', 'mcc', 'scity', 'stonc_tag', 'stonc_label', 'stonm_label', \n",
    "                 'stonc_6_label', 'stonc_10_label']\n",
    "\n",
    "numeric_cols = ['bnspt', 'timestamp_0', 'timestamp_1', 'objam']\n",
    "\n",
    "df_input = df_cdtx[category_cols + numeric_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time series.category_cols convert to index\n",
    "df_input.loc[:, category_cols[1:]] = df_input.loc[:, category_cols[1:]].astype(np.str)\n",
    "\n",
    "mapper = {col: {value: index+1 for index, value in enumerate(sorted(df_input[col].unique()))} \n",
    "          for col in category_cols[1:]}\n",
    "\n",
    "df_input[category_cols[1:]] = df_input[category_cols[1:]].apply(lambda x: x.map(mapper[x.name]))\n",
    "\n",
    "print(df_input.shape)\n",
    "df_input.head(2)\n",
    "\n",
    "for feat in mapper:\n",
    "    print(feat, len(mapper[feat]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user feature columns / each month\n",
    "# 相較於df_input，是來自於消費檔的資料，此處的資料是來自於崮客特徵檔。\n",
    "feat_category_cols = ['chid', 'masts', 'educd', 'trdtp', 'poscd']\n",
    "feat_numeric_cols = ['slam', 'first_mob', 'constant_change', 'sum_l2_ind', 'sum_u2_ind', 'constant_l2_ind', 'constant_u4_ind', \n",
    "                     'growth_rate', 'monotone_down', 'monotone_up']\n",
    "\n",
    "df_feat_input = df_cust_f[feat_category_cols + feat_numeric_cols + ['data_dt']].copy()\n",
    "df_feat_input.data_dt = df_feat_input.data_dt.astype(np.datetime64)\n",
    "\n",
    "print(df_feat_input.shape)\n",
    "df_feat_input.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user feature.category_cols convert to index\n",
    "df_feat_input.loc[:, feat_category_cols[1:]] = df_feat_input.loc[:, feat_category_cols[1:]].astype(np.str)\n",
    "\n",
    "feat_mapper = {col: {value: index+1 for index, value in enumerate(sorted(df_feat_input[col].unique()))} \n",
    "               for col in feat_category_cols[1:]}\n",
    "\n",
    "df_feat_input[feat_category_cols[1:]] = df_feat_input[feat_category_cols[1:]].apply(lambda x: x.map(feat_mapper[x.name]))\n",
    "\n",
    "print(df_feat_input.shape)\n",
    "df_feat_input.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in feat_mapper:\n",
    "    print(feat, len(feat_mapper[feat]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 從yf_full_y_sum裡面挑出target\n",
    "y_cols = ['chid', 'data_dt', 'objam_sum', 'objam_mean', 'trans_count', 'shop_count', 'objam_mean_M3']\n",
    "df_y = df_full_y_sum[y_cols].copy().reset_index(drop=True)\n",
    "\n",
    "print(df_y.shape)\n",
    "df_y.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(df_x, df_f, df_y, window_size, test_size=2):\n",
    "    df_x = df_x.copy()\n",
    "    df_f = df_f.copy()\n",
    "    df_y = df_y.copy()\n",
    "    \n",
    "    df_f['timestamp'] = (df_f.data_dt - np.datetime64('2018-01-01')).apply(lambda x: x.days).fillna(0)\n",
    "    df_y['timestamp'] = (df_y.data_dt - np.datetime64('2018-01-01')).apply(lambda x: x.days).fillna(0)\n",
    "    \n",
    "    x_train, x_test, f_train, f_test, y_train, y_test = [], [], [], [], [], []\n",
    "            \n",
    "    for i in tqdm(sorted(df_y.chid.unique())):\n",
    "        data_x = df_x[df_x.chid == i].reset_index(drop=True)\n",
    "        data_f = df_f[df_f.chid == i].reset_index(drop=True)\n",
    "        data_y = df_y[df_y.chid == i].reset_index(drop=True)\n",
    "        \n",
    "        last = data_y.shape[0] - 1\n",
    "        ts_list = sorted(data_y.timestamp.unique())\n",
    "        \n",
    "        for j, (ts_f, ts_y) in enumerate(zip(ts_list[:-1], ts_list[1:])):\n",
    "            data_x_ws = data_x[data_x.timestamp_1 < ts_y][-window_size:].copy()\n",
    "            data_x_ws.timestamp_1 = ts_y - data_x_ws.timestamp_1\n",
    "            data_x_ws = data_x_ws.values\n",
    "\n",
    "            if data_x_ws.shape[0] < window_size:\n",
    "                tmp = np.zeros((window_size, data_x.shape[1]))\n",
    "                if data_x_ws.shape[0] > 0:\n",
    "                    tmp[-data_x_ws.shape[0]:] = data_x_ws\n",
    "                data_x_ws = tmp\n",
    "\n",
    "            if j < last - test_size:\n",
    "                x_train.append(data_x_ws)\n",
    "                f_train.append(data_f[data_f.timestamp == ts_f].values[0, :-1])\n",
    "                y_train.append(data_y.values[j+1, :-1])\n",
    "            elif j < last:\n",
    "                x_test.append(data_x_ws)\n",
    "                f_test.append(data_f[data_f.timestamp == ts_f].values[0, :-1])\n",
    "                y_test.append(data_y.values[j+1, :-1])\n",
    "            else:\n",
    "                break        \n",
    "\n",
    "    x_train, x_test = np.array(x_train), np.array(x_test)\n",
    "    f_train, f_test = np.array(f_train), np.array(f_test)\n",
    "    y_train, y_test = np.array(y_train), np.array(y_test)\n",
    "    \n",
    "    return x_train, x_test, f_train, f_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_data，全資料\n",
    "# x: 代表交易資料\n",
    "# f: 代表顧客特徵資料 \n",
    "# y: 代表預測目標\n",
    "# input month: train -> 2018[1, 2, ..., 12]+2019[1, 2, ..., 9], test -> 2019[10, 11]\n",
    "x_train, x_test, f_train, f_test, y_train, y_test = data_split(df_input, df_feat_input, df_y, \n",
    "                                                               window_size=120, test_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_test.shape, f_train.shape, f_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_columns = list(df_y)\n",
    "y_columns[-1] = 'objam_mean_M3_diff'\n",
    "\n",
    "y_train[:, -1] = y_train[:, 2] - y_train[:, -1]\n",
    "y_test[:, -1] = y_test[:, 2] - y_test[:, -1]\n",
    "\n",
    "print(y_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(sample_path, 'RNN', 'x_train'), x_train)\n",
    "np.save(os.path.join(sample_path, 'RNN', 'x_test'), x_test)\n",
    "np.save(os.path.join(sample_path, 'RNN', 'f_train'), f_train)\n",
    "np.save(os.path.join(sample_path, 'RNN', 'f_test'), f_test)\n",
    "np.save(os.path.join(sample_path, 'RNN', 'y_train'), y_train)\n",
    "np.save(os.path.join(sample_path, 'RNN', 'y_test'), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(sample_path, 'RNN', 'feature_map'), mapper)\n",
    "np.save(os.path.join(sample_path, 'RNN', 'cust_feature_map'), feat_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {\n",
    "    'x_columns': list(df_input), \n",
    "    'f_columns': list(df_feat_input), \n",
    "    'y_columns': y_columns, \n",
    "}\n",
    "np.save(os.path.join(sample_path, 'RNN', 'columns'), columns)\n",
    "print(columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
