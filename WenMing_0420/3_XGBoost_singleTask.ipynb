{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from time import time\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(train_data, test_data, category_columns, numeric_columns, columns):\n",
    "    trans_index = [columns.index(cat) for cat in category_columns]\n",
    "    numeric_index = [columns.index(num) for num in numeric_columns]\n",
    "    \n",
    "    enc_list = [None]*len(category_columns)\n",
    "    train_data_list = [None]*len(category_columns)\n",
    "    test_data_list = [None]*len(category_columns)\n",
    "    new_columns = []\n",
    "    \n",
    "    for i, index in enumerate(trans_index):\n",
    "        enc_list[i] = OneHotEncoder(handle_unknown='ignore')\n",
    "        train_data_list[i] = enc_list[i].fit_transform(train_data[:, [index]]).toarray()\n",
    "        test_data_list[i] = enc_list[i].transform(test_data[:, [index]]).toarray()\n",
    "        \n",
    "        new_columns.extend([columns[index]+'_'+str(j) for j in range(len(enc_list[i].get_feature_names()))])\n",
    "\n",
    "    train_data_list.append(train_data[:, numeric_index])\n",
    "    test_data_list.append(test_data[:, numeric_index])\n",
    "    new_columns.extend(numeric_columns)\n",
    "    \n",
    "    trans_train_data = np.hstack(train_data_list)\n",
    "    trans_test_data = np.hstack(test_data_list)\n",
    "    \n",
    "    return trans_train_data, trans_test_data, enc_list, new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_xgb_model(dtrain, dtest, params, iteration=1000):\n",
    "    \n",
    "    t0 = time()\n",
    "    evals_result = dict()\n",
    "\n",
    "    xg_reg = xgb.train(params=params, \n",
    "                       dtrain=dtrain, \n",
    "                       num_boost_round=iteration,  \n",
    "                       early_stopping_rounds=100, \n",
    "                       evals=[(dtrain,'train'), (dtest,'test')], \n",
    "                       evals_result = evals_result,\n",
    "                       verbose_eval=50)\n",
    "    \n",
    "    print('training cost time:', time() - t0)\n",
    "    \n",
    "    return xg_reg, evals_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_regession_score(true, pred):\n",
    "    \n",
    "    scores = {\n",
    "        'RMSE': round(mean_squared_error(true, pred, squared=False), 2), \n",
    "        'MAE(mean)': round(mean_absolute_error(true, pred), 2), \n",
    "        'MAE(median)': round(median_absolute_error(true, pred), 2)\n",
    "    }    \n",
    "    \n",
    "    return scores\n",
    "\n",
    "def cal_classification_score(true, pred):\n",
    "    \n",
    "    scores = {\n",
    "        'AccuracyScore': round(accuracy_score(true, pred), 4), \n",
    "        'RecallScore': round(recall_score(true, pred, average='macro'), 4),\n",
    "        'PrecisionScore': round(precision_score(true, pred, average='macro'), 4),\n",
    "        'F1Score': round(f1_score(true, pred, average='macro'), 4),\n",
    "    }      \n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1033871, 541) (100000, 541) (1033871, 6) (100000, 6) 50000\n",
      "[('masts', 3), ('educd', 6), ('naty', 2), ('trdtp', 27), ('poscd', 9), ('cuorg', 30)]\n"
     ]
    }
   ],
   "source": [
    "sample_path = './data/sample_50k'\n",
    "\n",
    "x_train = np.load(os.path.join(sample_path, 'Normal', 'x_train.npy'), allow_pickle=True)\n",
    "x_test = np.load(os.path.join(sample_path, 'Normal', 'x_test.npy'), allow_pickle=True)\n",
    "\n",
    "Y_train = np.load(os.path.join(sample_path, 'Normal', 'y_train.npy'), allow_pickle=True)\n",
    "Y_test = np.load(os.path.join(sample_path, 'Normal', 'y_test.npy'), allow_pickle=True)\n",
    "\n",
    "chid_mapper = np.load(os.path.join(sample_path, 'sample_50k_chid_idx_map.npy'), allow_pickle=True).item()\n",
    "feat_mapper = np.load(os.path.join(sample_path, 'Normal', 'feature_map.npy'), allow_pickle=True).item()\n",
    "\n",
    "columns = np.load(os.path.join(sample_path, 'Normal', 'columns.npy'), allow_pickle=True).item()\n",
    "\n",
    "print(x_train.shape, x_test.shape, Y_train.shape, Y_test.shape, len(chid_mapper))\n",
    "print([(k, len(v)) for k, v in feat_mapper.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chid', 'data_dt', 'objam_sum', 'objam_mean', 'trans_count', 'shop_count']\n"
     ]
    }
   ],
   "source": [
    "print(columns['y_columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chid', 'masts', 'educd', 'naty', 'trdtp', 'poscd', 'cuorg'] 534\n"
     ]
    }
   ],
   "source": [
    "category_cols = columns['x_columns'][:7]\n",
    "numeric_cols = columns['x_columns'][7:-1]\n",
    "\n",
    "print(category_cols, len(numeric_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1033871, 611), (100000, 611), 611)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_x_train, trans_x_test, enc_list, trans_columns = to_one_hot(x_train, x_test, category_cols[1:], numeric_cols[:], \n",
    "                                                                  columns['x_columns'][:-1])\n",
    "trans_x_train.shape, trans_x_test.shape, len(trans_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## objam_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ['reg:reg:squarederror', 'reg:squaredlogerror']\n",
    "## ['multi:softmax', 'multi:softprob']\n",
    "\n",
    "params = {'objective':'reg:squarederror', 'learning_rate': 0.05, 'max_depth': 5, \n",
    "          'subsample':0.7, 'min_child_weight':4, 'eval_metric':'rmse', 'n_jobs':40}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regession\n",
    "index = columns['y_columns'].index('objam_sum')\n",
    "train_objsum = Y_train[:, [index]].astype(np.float64)\n",
    "test_objsum = Y_test[:, [index]].astype(np.float64)\n",
    "\n",
    "dtrain = xgb.DMatrix(data=trans_x_train, label=train_objsum, feature_names=trans_columns)\n",
    "dtest  = xgb.DMatrix(data=trans_x_test, label=test_objsum, feature_names=trans_columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:847072.56250\ttest-rmse:612736.43750\n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 100 rounds.\n",
      "[50]\ttrain-rmse:776249.06250\ttest-rmse:505209.62500\n",
      "[100]\ttrain-rmse:765608.12500\ttest-rmse:495661.59375\n",
      "[150]\ttrain-rmse:758501.75000\ttest-rmse:488269.18750\n",
      "[200]\ttrain-rmse:753843.31250\ttest-rmse:488051.56250\n",
      "[250]\ttrain-rmse:749900.06250\ttest-rmse:487316.46875\n",
      "[300]\ttrain-rmse:746428.50000\ttest-rmse:484258.90625\n",
      "[350]\ttrain-rmse:743447.25000\ttest-rmse:483936.12500\n",
      "[400]\ttrain-rmse:735649.00000\ttest-rmse:484672.06250\n",
      "Stopping. Best iteration:\n",
      "[334]\ttrain-rmse:744354.87500\ttest-rmse:482252.00000\n",
      "\n",
      "training cost time: 492.8558645248413\n"
     ]
    }
   ],
   "source": [
    "xg_objsum, evals_result = build_xgb_model(dtrain, dtest, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1033871,), (100000,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred = xg_objsum.predict(dtrain, ntree_limit=xg_objsum.best_ntree_limit)\n",
    "test_pred = xg_objsum.predict(dtest, ntree_limit=xg_objsum.best_ntree_limit)\n",
    "\n",
    "train_pred.shape, test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'RMSE': 744367.25, 'MAE(mean)': 77246.84, 'MAE(median)': 29321.8},\n",
       " {'RMSE': 482252.1, 'MAE(mean)': 85155.9, 'MAE(median)': 29321.8})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores = cal_regession_score(train_pred, dtrain.get_label())\n",
    "test_scores = cal_regession_score(test_pred, dtest.get_label())\n",
    "\n",
    "train_scores, test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trans_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ['reg:reg:squarederror', 'reg:squaredlogerror']\n",
    "## ['multi:softmax', 'multi:softprob']\n",
    "\n",
    "params = {'objective':'reg:squarederror', 'learning_rate': 0.05, 'max_depth': 5, \n",
    "          'subsample':0.7, 'min_child_weight':4, 'eval_metric':'rmse', 'n_jobs':40}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regession\n",
    "index = columns['y_columns'].index('trans_count')\n",
    "train_tscnt = Y_train[:, [index]].astype(np.float64)\n",
    "test_tscnt = Y_test[:, [index]].astype(np.float64)\n",
    "\n",
    "dtrain = xgb.DMatrix(data=trans_x_train, label=train_tscnt, feature_names=trans_columns)\n",
    "dtest  = xgb.DMatrix(data=trans_x_test, label=test_tscnt, feature_names=trans_columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:9.79032\ttest-rmse:18.08149\n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 100 rounds.\n",
      "[50]\ttrain-rmse:4.78807\ttest-rmse:10.16167\n",
      "[100]\ttrain-rmse:4.59638\ttest-rmse:9.56393\n",
      "[150]\ttrain-rmse:4.53524\ttest-rmse:9.54441\n",
      "[200]\ttrain-rmse:4.48769\ttest-rmse:9.56729\n",
      "[250]\ttrain-rmse:4.44222\ttest-rmse:9.58942\n",
      "Stopping. Best iteration:\n",
      "[157]\ttrain-rmse:4.52940\ttest-rmse:9.49582\n",
      "\n",
      "training cost time: 278.20790338516235\n"
     ]
    }
   ],
   "source": [
    "xg_tscnt, evals_result = build_xgb_model(dtrain, dtest, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1033871,), (100000,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred = xg_tscnt.predict(dtrain, ntree_limit=xg_tscnt.best_ntree_limit)\n",
    "test_pred = xg_tscnt.predict(dtest, ntree_limit=xg_tscnt.best_ntree_limit)\n",
    "\n",
    "train_pred.shape, test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'RMSE': 4.53, 'MAE(mean)': 2.42, 'MAE(median)': 1.29},\n",
       " {'RMSE': 9.5, 'MAE(mean)': 2.81, 'MAE(median)': 1.3})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores = cal_regession_score(train_pred, dtrain.get_label())\n",
    "test_scores = cal_regession_score(test_pred, dtest.get_label())\n",
    "\n",
    "train_scores, test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shop_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ['reg:reg:squarederror', 'reg:squaredlogerror']\n",
    "## ['multi:softmax', 'multi:softprob']\n",
    "\n",
    "params = {'objective':'reg:squarederror', 'learning_rate': 0.1, 'max_depth': 5, \n",
    "          'subsample':0.7, 'min_child_weight':4, 'eval_metric':'rmse', 'n_jobs':40}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regession\n",
    "index = columns['y_columns'].index('shop_count')\n",
    "train_spcnt = Y_train[:, [index]].astype(np.float64)\n",
    "test_spcnt = Y_test[:, [index]].astype(np.float64)\n",
    "\n",
    "dtrain = xgb.DMatrix(data=trans_x_train, label=train_spcnt, feature_names=trans_columns)\n",
    "dtest  = xgb.DMatrix(data=trans_x_test, label=test_spcnt, feature_names=trans_columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:3.81768\ttest-rmse:4.83613\n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 100 rounds.\n",
      "[50]\ttrain-rmse:2.07166\ttest-rmse:2.32030\n",
      "[100]\ttrain-rmse:2.05293\ttest-rmse:2.30616\n",
      "[150]\ttrain-rmse:2.04326\ttest-rmse:2.30398\n",
      "[200]\ttrain-rmse:2.03537\ttest-rmse:2.30258\n",
      "[250]\ttrain-rmse:2.02962\ttest-rmse:2.30102\n",
      "[300]\ttrain-rmse:2.02414\ttest-rmse:2.30076\n",
      "[350]\ttrain-rmse:2.01934\ttest-rmse:2.30025\n",
      "[400]\ttrain-rmse:2.01482\ttest-rmse:2.30031\n",
      "Stopping. Best iteration:\n",
      "[345]\ttrain-rmse:2.01974\ttest-rmse:2.30004\n",
      "\n",
      "training cost time: 485.8045542240143\n"
     ]
    }
   ],
   "source": [
    "xg_spcnt, evals_result = build_xgb_model(dtrain, dtest, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1033871,), (100000,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred = xg_spcnt.predict(dtrain, ntree_limit=xg_spcnt.best_ntree_limit)\n",
    "test_pred = xg_spcnt.predict(dtest, ntree_limit=xg_spcnt.best_ntree_limit)\n",
    "\n",
    "train_pred.shape, test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'RMSE': 2.02, 'MAE(mean)': 1.32, 'MAE(median)': 0.81},\n",
       " {'RMSE': 2.3, 'MAE(mean)': 1.44, 'MAE(median)': 0.81})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores = cal_regession_score(train_pred, dtrain.get_label())\n",
    "test_scores = cal_regession_score(test_pred, dtest.get_label())\n",
    "\n",
    "train_scores, test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## label_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ['reg:reg:squarederror', 'reg:squaredlogerror']\n",
    "## ['binary:logistic', 'multi:softmax', 'multi:softprob']\n",
    "\n",
    "params = {'objective':'multi:softmax', 'learning_rate': 0.1, 'max_depth': 5, \n",
    "          'subsample':0.7, 'min_child_weight':4, 'eval_metric':'merror', 'num_class':2, 'n_jobs':40}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2 (1033871, 1) (100000, 1)\n"
     ]
    }
   ],
   "source": [
    "#classfication\n",
    "bounds = [0]\n",
    "lable_trans = np.vectorize(lambda x: sum([x > bound for bound in bounds]))\n",
    "\n",
    "train_label_0 = lable_trans(train_objsum)\n",
    "test_label_0 = lable_trans(test_objsum)\n",
    "\n",
    "dtrain = xgb.DMatrix(data=trans_x_train, label=train_label_0, feature_names=trans_columns)\n",
    "dtest  = xgb.DMatrix(data=trans_x_test, label=test_label_0, feature_names=trans_columns) \n",
    "\n",
    "print(np.unique(train_label_0).shape[0], np.unique(test_label_0).shape[0], train_label_0.shape, test_label_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.18071\ttest-merror:0.15964\n",
      "Multiple eval metrics have been passed: 'test-merror' will be used for early stopping.\n",
      "\n",
      "Will train until test-merror hasn't improved in 100 rounds.\n",
      "[50]\ttrain-merror:0.17893\ttest-merror:0.15876\n",
      "[100]\ttrain-merror:0.17824\ttest-merror:0.15833\n",
      "[150]\ttrain-merror:0.17778\ttest-merror:0.15817\n",
      "[200]\ttrain-merror:0.17732\ttest-merror:0.15787\n",
      "[250]\ttrain-merror:0.17706\ttest-merror:0.15775\n",
      "[300]\ttrain-merror:0.17686\ttest-merror:0.15766\n",
      "[350]\ttrain-merror:0.17661\ttest-merror:0.15752\n",
      "[400]\ttrain-merror:0.17645\ttest-merror:0.15752\n",
      "[450]\ttrain-merror:0.17626\ttest-merror:0.15759\n",
      "Stopping. Best iteration:\n",
      "[362]\ttrain-merror:0.17660\ttest-merror:0.15743\n",
      "\n",
      "training cost time: 996.2755992412567\n"
     ]
    }
   ],
   "source": [
    "xg_label_0, evals_result = build_xgb_model(dtrain, dtest, params, iteration=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1033871,), (100000,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred = xg_label_0.predict(dtrain, ntree_limit=xg_label_0.best_ntree_limit)\n",
    "test_pred = xg_label_0.predict(dtest, ntree_limit=xg_label_0.best_ntree_limit)\n",
    "\n",
    "train_pred.shape, test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'AccuracyScore': 0.8234,\n",
       "  'RecallScore': 0.7886,\n",
       "  'PrecisionScore': 0.7797,\n",
       "  'F1Score': 0.7839},\n",
       " {'AccuracyScore': 0.8426,\n",
       "  'RecallScore': 0.8128,\n",
       "  'PrecisionScore': 0.8062,\n",
       "  'F1Score': 0.8093})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores = cal_classification_score(train_pred, dtrain.get_label())\n",
    "test_scores = cal_classification_score(test_pred, dtest.get_label())\n",
    "\n",
    "train_scores, test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## label_multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ['reg:reg:squarederror', 'reg:squaredlogerror']\n",
    "## ['binary:logistic', 'multi:softmax', 'multi:softprob']\n",
    "\n",
    "params = {'objective':'multi:softmax', 'learning_rate': 0.08, 'max_depth': 5, \n",
    "          'subsample':0.7, 'min_child_weight':4, 'eval_metric':'merror', 'num_class':6, 'n_jobs':40}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6 (1033871, 1) (100000, 1)\n"
     ]
    }
   ],
   "source": [
    "bounds = [0, 1e4, 5e4, 1e5, 3e5]\n",
    "lable_trans = np.vectorize(lambda x: sum([x > bound for bound in bounds]))\n",
    "train_label_mul = lable_trans(train_objsum)\n",
    "test_label_mul = lable_trans(test_objsum)\n",
    "\n",
    "dtrain = xgb.DMatrix(data=trans_x_train, label=train_label_mul, feature_names=trans_columns)\n",
    "dtest  = xgb.DMatrix(data=trans_x_test, label=test_label_mul, feature_names=trans_columns) \n",
    "\n",
    "print(np.unique(train_label_mul).shape[0], np.unique(test_label_mul).shape[0], train_label_mul.shape, test_label_mul.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.49944\ttest-merror:0.48353\n",
      "Multiple eval metrics have been passed: 'test-merror' will be used for early stopping.\n",
      "\n",
      "Will train until test-merror hasn't improved in 100 rounds.\n",
      "[50]\ttrain-merror:0.49168\ttest-merror:0.47659\n",
      "[100]\ttrain-merror:0.48823\ttest-merror:0.47435\n",
      "[150]\ttrain-merror:0.48600\ttest-merror:0.47331\n",
      "[200]\ttrain-merror:0.48409\ttest-merror:0.47214\n",
      "[250]\ttrain-merror:0.48269\ttest-merror:0.47142\n",
      "[300]\ttrain-merror:0.48140\ttest-merror:0.47121\n",
      "[350]\ttrain-merror:0.48036\ttest-merror:0.47130\n",
      "[400]\ttrain-merror:0.47921\ttest-merror:0.47108\n",
      "[450]\ttrain-merror:0.47816\ttest-merror:0.47043\n",
      "[500]\ttrain-merror:0.47727\ttest-merror:0.47038\n",
      "[550]\ttrain-merror:0.47633\ttest-merror:0.47018\n",
      "[600]\ttrain-merror:0.47543\ttest-merror:0.46996\n",
      "Stopping. Best iteration:\n",
      "[532]\ttrain-merror:0.47667\ttest-merror:0.46994\n",
      "\n",
      "training cost time: 4256.379280328751\n"
     ]
    }
   ],
   "source": [
    "xg_label_mul, evals_result = build_xgb_model(dtrain, dtest, params, iteration=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1033871,), (100000,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred = xg_label_mul.predict(dtrain, ntree_limit=xg_label_mul.best_ntree_limit)\n",
    "test_pred = xg_label_mul.predict(dtest, ntree_limit=xg_label_mul.best_ntree_limit)\n",
    "\n",
    "train_pred.shape, test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'AccuracyScore': 0.5233,\n",
       "  'RecallScore': 0.5044,\n",
       "  'PrecisionScore': 0.3988,\n",
       "  'F1Score': 0.4083},\n",
       " {'AccuracyScore': 0.5301,\n",
       "  'RecallScore': 0.4927,\n",
       "  'PrecisionScore': 0.4119,\n",
       "  'F1Score': 0.4176})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores = cal_classification_score(train_pred, dtrain.get_label())\n",
    "test_scores = cal_classification_score(test_pred, dtest.get_label())\n",
    "\n",
    "train_scores, test_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
